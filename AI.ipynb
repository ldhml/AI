{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNvwRWdJNZttwwEFUCJlEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldhml/AI/blob/main/AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "3OBixoom7-8J",
        "outputId": "09778da7-d19c-4641-ec87-4561b3fc667a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-55d3c55b6f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnew_d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.35\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "s=svm.SVC(gamma=0.1,C=10)\n",
        "s.fit(d.data,d.target)\n",
        "\n",
        "new_d=[[6.4,3.2,6.0,2.5],[7.1,3.1,4.7,1.35]]\n",
        "\n",
        "res=s.predict(new_d)\n",
        "print(\"새로운 2개 샘플의 부류는\",res)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "d=datasets.load_iris() #iris 데이터셋을 읽고\n",
        "print(d.DESCR) #내용을 출력\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Eh9AbFcAm18",
        "outputId": "b5b76a62-0cc4-4965-96c5-a7b54a2ca38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(d.data)): #샘플을 순서대로 출력\n",
        "  print(i+1,d.data[i],d.target[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJYTJrT_Apaj",
        "outputId": "55693b5a-5a2a-4317-d6a4-8331ef09627d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 [5.1 3.5 1.4 0.2] 0\n",
            "2 [4.9 3.  1.4 0.2] 0\n",
            "3 [4.7 3.2 1.3 0.2] 0\n",
            "4 [4.6 3.1 1.5 0.2] 0\n",
            "5 [5.  3.6 1.4 0.2] 0\n",
            "6 [5.4 3.9 1.7 0.4] 0\n",
            "7 [4.6 3.4 1.4 0.3] 0\n",
            "8 [5.  3.4 1.5 0.2] 0\n",
            "9 [4.4 2.9 1.4 0.2] 0\n",
            "10 [4.9 3.1 1.5 0.1] 0\n",
            "11 [5.4 3.7 1.5 0.2] 0\n",
            "12 [4.8 3.4 1.6 0.2] 0\n",
            "13 [4.8 3.  1.4 0.1] 0\n",
            "14 [4.3 3.  1.1 0.1] 0\n",
            "15 [5.8 4.  1.2 0.2] 0\n",
            "16 [5.7 4.4 1.5 0.4] 0\n",
            "17 [5.4 3.9 1.3 0.4] 0\n",
            "18 [5.1 3.5 1.4 0.3] 0\n",
            "19 [5.7 3.8 1.7 0.3] 0\n",
            "20 [5.1 3.8 1.5 0.3] 0\n",
            "21 [5.4 3.4 1.7 0.2] 0\n",
            "22 [5.1 3.7 1.5 0.4] 0\n",
            "23 [4.6 3.6 1.  0.2] 0\n",
            "24 [5.1 3.3 1.7 0.5] 0\n",
            "25 [4.8 3.4 1.9 0.2] 0\n",
            "26 [5.  3.  1.6 0.2] 0\n",
            "27 [5.  3.4 1.6 0.4] 0\n",
            "28 [5.2 3.5 1.5 0.2] 0\n",
            "29 [5.2 3.4 1.4 0.2] 0\n",
            "30 [4.7 3.2 1.6 0.2] 0\n",
            "31 [4.8 3.1 1.6 0.2] 0\n",
            "32 [5.4 3.4 1.5 0.4] 0\n",
            "33 [5.2 4.1 1.5 0.1] 0\n",
            "34 [5.5 4.2 1.4 0.2] 0\n",
            "35 [4.9 3.1 1.5 0.2] 0\n",
            "36 [5.  3.2 1.2 0.2] 0\n",
            "37 [5.5 3.5 1.3 0.2] 0\n",
            "38 [4.9 3.6 1.4 0.1] 0\n",
            "39 [4.4 3.  1.3 0.2] 0\n",
            "40 [5.1 3.4 1.5 0.2] 0\n",
            "41 [5.  3.5 1.3 0.3] 0\n",
            "42 [4.5 2.3 1.3 0.3] 0\n",
            "43 [4.4 3.2 1.3 0.2] 0\n",
            "44 [5.  3.5 1.6 0.6] 0\n",
            "45 [5.1 3.8 1.9 0.4] 0\n",
            "46 [4.8 3.  1.4 0.3] 0\n",
            "47 [5.1 3.8 1.6 0.2] 0\n",
            "48 [4.6 3.2 1.4 0.2] 0\n",
            "49 [5.3 3.7 1.5 0.2] 0\n",
            "50 [5.  3.3 1.4 0.2] 0\n",
            "51 [7.  3.2 4.7 1.4] 1\n",
            "52 [6.4 3.2 4.5 1.5] 1\n",
            "53 [6.9 3.1 4.9 1.5] 1\n",
            "54 [5.5 2.3 4.  1.3] 1\n",
            "55 [6.5 2.8 4.6 1.5] 1\n",
            "56 [5.7 2.8 4.5 1.3] 1\n",
            "57 [6.3 3.3 4.7 1.6] 1\n",
            "58 [4.9 2.4 3.3 1. ] 1\n",
            "59 [6.6 2.9 4.6 1.3] 1\n",
            "60 [5.2 2.7 3.9 1.4] 1\n",
            "61 [5.  2.  3.5 1. ] 1\n",
            "62 [5.9 3.  4.2 1.5] 1\n",
            "63 [6.  2.2 4.  1. ] 1\n",
            "64 [6.1 2.9 4.7 1.4] 1\n",
            "65 [5.6 2.9 3.6 1.3] 1\n",
            "66 [6.7 3.1 4.4 1.4] 1\n",
            "67 [5.6 3.  4.5 1.5] 1\n",
            "68 [5.8 2.7 4.1 1. ] 1\n",
            "69 [6.2 2.2 4.5 1.5] 1\n",
            "70 [5.6 2.5 3.9 1.1] 1\n",
            "71 [5.9 3.2 4.8 1.8] 1\n",
            "72 [6.1 2.8 4.  1.3] 1\n",
            "73 [6.3 2.5 4.9 1.5] 1\n",
            "74 [6.1 2.8 4.7 1.2] 1\n",
            "75 [6.4 2.9 4.3 1.3] 1\n",
            "76 [6.6 3.  4.4 1.4] 1\n",
            "77 [6.8 2.8 4.8 1.4] 1\n",
            "78 [6.7 3.  5.  1.7] 1\n",
            "79 [6.  2.9 4.5 1.5] 1\n",
            "80 [5.7 2.6 3.5 1. ] 1\n",
            "81 [5.5 2.4 3.8 1.1] 1\n",
            "82 [5.5 2.4 3.7 1. ] 1\n",
            "83 [5.8 2.7 3.9 1.2] 1\n",
            "84 [6.  2.7 5.1 1.6] 1\n",
            "85 [5.4 3.  4.5 1.5] 1\n",
            "86 [6.  3.4 4.5 1.6] 1\n",
            "87 [6.7 3.1 4.7 1.5] 1\n",
            "88 [6.3 2.3 4.4 1.3] 1\n",
            "89 [5.6 3.  4.1 1.3] 1\n",
            "90 [5.5 2.5 4.  1.3] 1\n",
            "91 [5.5 2.6 4.4 1.2] 1\n",
            "92 [6.1 3.  4.6 1.4] 1\n",
            "93 [5.8 2.6 4.  1.2] 1\n",
            "94 [5.  2.3 3.3 1. ] 1\n",
            "95 [5.6 2.7 4.2 1.3] 1\n",
            "96 [5.7 3.  4.2 1.2] 1\n",
            "97 [5.7 2.9 4.2 1.3] 1\n",
            "98 [6.2 2.9 4.3 1.3] 1\n",
            "99 [5.1 2.5 3.  1.1] 1\n",
            "100 [5.7 2.8 4.1 1.3] 1\n",
            "101 [6.3 3.3 6.  2.5] 2\n",
            "102 [5.8 2.7 5.1 1.9] 2\n",
            "103 [7.1 3.  5.9 2.1] 2\n",
            "104 [6.3 2.9 5.6 1.8] 2\n",
            "105 [6.5 3.  5.8 2.2] 2\n",
            "106 [7.6 3.  6.6 2.1] 2\n",
            "107 [4.9 2.5 4.5 1.7] 2\n",
            "108 [7.3 2.9 6.3 1.8] 2\n",
            "109 [6.7 2.5 5.8 1.8] 2\n",
            "110 [7.2 3.6 6.1 2.5] 2\n",
            "111 [6.5 3.2 5.1 2. ] 2\n",
            "112 [6.4 2.7 5.3 1.9] 2\n",
            "113 [6.8 3.  5.5 2.1] 2\n",
            "114 [5.7 2.5 5.  2. ] 2\n",
            "115 [5.8 2.8 5.1 2.4] 2\n",
            "116 [6.4 3.2 5.3 2.3] 2\n",
            "117 [6.5 3.  5.5 1.8] 2\n",
            "118 [7.7 3.8 6.7 2.2] 2\n",
            "119 [7.7 2.6 6.9 2.3] 2\n",
            "120 [6.  2.2 5.  1.5] 2\n",
            "121 [6.9 3.2 5.7 2.3] 2\n",
            "122 [5.6 2.8 4.9 2. ] 2\n",
            "123 [7.7 2.8 6.7 2. ] 2\n",
            "124 [6.3 2.7 4.9 1.8] 2\n",
            "125 [6.7 3.3 5.7 2.1] 2\n",
            "126 [7.2 3.2 6.  1.8] 2\n",
            "127 [6.2 2.8 4.8 1.8] 2\n",
            "128 [6.1 3.  4.9 1.8] 2\n",
            "129 [6.4 2.8 5.6 2.1] 2\n",
            "130 [7.2 3.  5.8 1.6] 2\n",
            "131 [7.4 2.8 6.1 1.9] 2\n",
            "132 [7.9 3.8 6.4 2. ] 2\n",
            "133 [6.4 2.8 5.6 2.2] 2\n",
            "134 [6.3 2.8 5.1 1.5] 2\n",
            "135 [6.1 2.6 5.6 1.4] 2\n",
            "136 [7.7 3.  6.1 2.3] 2\n",
            "137 [6.3 3.4 5.6 2.4] 2\n",
            "138 [6.4 3.1 5.5 1.8] 2\n",
            "139 [6.  3.  4.8 1.8] 2\n",
            "140 [6.9 3.1 5.4 2.1] 2\n",
            "141 [6.7 3.1 5.6 2.4] 2\n",
            "142 [6.9 3.1 5.1 2.3] 2\n",
            "143 [5.8 2.7 5.1 1.9] 2\n",
            "144 [6.8 3.2 5.9 2.3] 2\n",
            "145 [6.7 3.3 5.7 2.5] 2\n",
            "146 [6.7 3.  5.2 2.3] 2\n",
            "147 [6.3 2.5 5.  1.9] 2\n",
            "148 [6.5 3.  5.2 2. ] 2\n",
            "149 [6.2 3.4 5.4 2.3] 2\n",
            "150 [5.9 3.  5.1 1.8] 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "s=svm.SVC(gamma=0.1,C=10)\n",
        "s.fit(d.data,d.target)\n",
        "\n",
        "new_d=[[6.4,3.2,6.0,2.5],[7.57,3.1,4.7,1.3]]\n",
        "\n",
        "res=s.predict(new_d)\n",
        "print(\"새로운 2개 샘플의 부류는\",res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkKlvQe6ArrL",
        "outputId": "c6d1b784-893d-49d6-8228-5ed5a3be83ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "새로운 2개 샘플의 부류는 [2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "df=px.data.iris()\n",
        "fig=px.scatter_3d(df,x='petal_length',y='sepal_length',z='petal_width',color='species')\n",
        "fig.show()\n",
        "#전체적으로 세 부류가 겹침\n",
        "#petal width와 petal length가 많이 겹침-> 분별력이 낮음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "lBoy7B_aAumz",
        "outputId": "7e748f6d-49d5-4968-b0a1-8340f22f7c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"8e4a401c-f1bd-42cc-ac20-14d8ee2817dd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8e4a401c-f1bd-42cc-ac20-14d8ee2817dd\")) {                    Plotly.newPlot(                        \"8e4a401c-f1bd-42cc-ac20-14d8ee2817dd\",                        [{\"hovertemplate\":\"species=setosa<br>petal_length=%{x}<br>sepal_length=%{y}<br>petal_width=%{z}<extra></extra>\",\"legendgroup\":\"setosa\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"setosa\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1.0,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.5,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4],\"y\":[5.1,4.9,4.7,4.6,5.0,5.4,4.6,5.0,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5.0,5.0,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5.0,5.5,4.9,4.4,5.1,5.0,4.5,4.4,5.0,5.1,4.8,5.1,4.6,5.3,5.0],\"z\":[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.1,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2],\"type\":\"scatter3d\"},{\"hovertemplate\":\"species=versicolor<br>petal_length=%{x}<br>sepal_length=%{y}<br>petal_width=%{z}<extra></extra>\",\"legendgroup\":\"versicolor\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"versicolor\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[4.7,4.5,4.9,4.0,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4.0,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4.0,4.9,4.7,4.3,4.4,4.8,5.0,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4.0,4.4,4.6,4.0,3.3,4.2,4.2,4.2,4.3,3.0,4.1],\"y\":[7.0,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5.0,5.9,6.0,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6.0,5.7,5.5,5.5,5.8,6.0,5.4,6.0,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5.0,5.6,5.7,5.7,6.2,5.1,5.7],\"z\":[1.4,1.5,1.5,1.3,1.5,1.3,1.6,1.0,1.3,1.4,1.0,1.5,1.0,1.4,1.3,1.4,1.5,1.0,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1.0,1.1,1.0,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1.0,1.3,1.2,1.3,1.3,1.1,1.3],\"type\":\"scatter3d\"},{\"hovertemplate\":\"species=virginica<br>petal_length=%{x}<br>sepal_length=%{y}<br>petal_width=%{z}<extra></extra>\",\"legendgroup\":\"virginica\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"virginica\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[6.0,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5.0,5.1,5.3,5.5,6.7,6.9,5.0,5.7,4.9,6.7,4.9,5.7,6.0,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5.0,5.2,5.4,5.1],\"y\":[6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6.0,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6.0,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],\"z\":[2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2.0,1.9,2.1,2.0,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2.0,2.0,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2.0,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2.0,2.3,1.8],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"petal_length\"}},\"yaxis\":{\"title\":{\"text\":\"sepal_length\"}},\"zaxis\":{\"title\":{\"text\":\"petal_width\"}}},\"legend\":{\"title\":{\"text\":\"species\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8e4a401c-f1bd-42cc-ac20-14d8ee2817dd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 준비\n",
        "filepath = '/content/lemonade.csv'\n",
        "lemonade = pd.read_csv(filepath)\n",
        "lemonade.head()\n",
        "\n",
        "# 종속변수, 독립변수\n",
        "독립 = lemonade[['온도']]\n",
        "종속 = lemonade[['판매량']]\n",
        "#print(lemondade.shape) #(6, 2)\n",
        "#print(독립 .shape, 종속.shape) #(6, 1) (6, 1)\n",
        "\n",
        "# 모델 생성\n",
        "X = tf.keras.layers.Input(shape=[1])\n",
        "Y = tf.keras.layers.Dense(1)(X)\n",
        "model = tf.keras.models.Model(X, Y)\n",
        "model.compile(loss='mse')\n",
        "\n",
        "# 모델 학습\n",
        "# verbose=0: 학습하는 동안에 안보임\n",
        "model.fit(독립, 종속, epochs=1000, verbose=0)\n",
        "model.fit(독립, 종속, epochs=10)\n",
        "\n",
        "# 모델 예측(이용)\n",
        "print(model.predict(독립))\n",
        "print(model.predict([[15]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VRl-N8M6KJa",
        "outputId": "d1cd57d9-c283-4327-cc28-492e1b67c4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1683.0250\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1681.1025\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1679.1810\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1677.2603\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1675.3408\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1673.4225\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1671.5052\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 1669.5890\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1667.6740\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1665.7603\n",
            "[[3.9639826]\n",
            " [4.111429 ]\n",
            " [4.258876 ]\n",
            " [4.4063225]\n",
            " [4.553769 ]\n",
            " [4.7012153]]\n",
            "[[3.22675]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#보스톤 집값\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "#1.과거 데이터 준비\n",
        "filepath='/content/boston.csv'\n",
        "boston=pd.read_csv(filepath)\n",
        "#print(boston.columns)\n",
        "boston.head()\n",
        "\n",
        "#독립\n",
        "independent=boston[['crim','zn','indus','chas','nox','rm','age','dis','rad','tax','ptratio','b','lstat']]\n",
        "\n",
        "#종속\n",
        "dependent=boston[['medv']]\n",
        "#print(independent.shape,dependent.shape)\n",
        "\n",
        "#2.모델 구조 생성\n",
        "X=tf.keras.layers.Input(shape=[13])\n",
        "H=tf.keras.layers.Dense(10,activation='swish')(X)\n",
        "Y=tf.keras.layers.Dense(1)(H)\n",
        "model=tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='mse')\n",
        "\n",
        "#모델 구조 확인\n",
        "model.summary()\n",
        "\n",
        "#3. 모델 학습(FIT)\n",
        "model.fit(independent,dependent,epochs=100,verbose=0)\n",
        "#model.fit(independent,dependent,epochs=10)\n",
        "\n",
        "#4.모델 이용(예측)\n",
        "print(model.predict(independent[5:10]))\n",
        "#종속변수 확인\n",
        "print(dependent[5:10])\n",
        "\n",
        "#모델 수식 확인\n",
        "#print(model.get_weights())\n",
        "\n",
        "#결과분석 \n",
        "#Param#은 가중치이다.\n",
        "#Output Shape에서 None옆의 값들은 위에서 준 값임 즉 X,H,Y에 넣어져 있는 값. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFw3pXjIA5vM",
        "outputId": "ca89a95b-99d1-4d2b-c658-5c7a599b705e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 13)]              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                140       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 151\n",
            "Trainable params: 151\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0a6c7b6b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[28.428902]\n",
            " [24.323214]\n",
            " [21.884588]\n",
            " [17.083632]\n",
            " [21.577085]]\n",
            "   medv\n",
            "5  28.7\n",
            "6  22.9\n",
            "7  27.1\n",
            "8  16.5\n",
            "9  18.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "#1.과거 데이터 준비\n",
        "filepath='/content/iris.csv'\n",
        "iris=pd.read_csv(filepath)\n",
        "iris.head()\n",
        "\n",
        "#ond-hot encoding\n",
        "after_encoding=pd.get_dummies(iris)\n",
        "after_encoding.head()\n",
        "print(after_encoding)\n",
        "\n",
        "#독립변수, 종속변수\n",
        "independent=after_encoding[['꽃잎길이','꽃잎폭','꽃받침길이','꽃받침폭']]\n",
        "dependent=after_encoding[['품종_setosa','품종_versicolor','품종_virginica']]\n",
        "print(independent.shape,dependent.shape)\n",
        "\n",
        "#2.모델구조\n",
        "X=tf.keras.layers.Input(shape=[4])\n",
        "Y=tf.keras.layers.Dense(3,activation='softmax')(X) #Dense는 자기를 써라 ,옆에 3은 출력을 3개만 하라\n",
        "model=tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "#3.모델 학습(FIT)\n",
        "model.fit(independent,dependent,epochs=90,verbose=0) #independent는 독립변수, dependent는 종속변수 epochs은 학습을 몇번 시키는지\n",
        "model.fit(independent,dependent,epochs=10)\n",
        "\n",
        "#모델 이용, 맨 처음 데이터 5개\n",
        "print(model.predict(independent[:5]))\n",
        "print(dependent[:5])#dependent 정답에 5개 까지만 출력하라\n",
        "\n",
        "#weight & bias출력\n",
        "print(model.get_weights()) #get weights는 결과물이 어떨지 찍어본거임 \n",
        "\n",
        "#결과물 분석\n",
        "#결과물 0.38...여기서 왜 옆으로 3개씩 되어있냐면 위에 원합인코딩으로 dense함수와 3을 써서 결과물에 3개만 쓰개 나타냈다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajkwXuDPFsze",
        "outputId": "2cf5bf61-4369-43cb-94a1-43f18b336780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭  품종_setosa  품종_versicolor  품종_virginica\n",
            "0     5.1  3.5    1.4   0.2          1              0             0\n",
            "1     4.9  3.0    1.4   0.2          1              0             0\n",
            "2     4.7  3.2    1.3   0.2          1              0             0\n",
            "3     4.6  3.1    1.5   0.2          1              0             0\n",
            "4     5.0  3.6    1.4   0.2          1              0             0\n",
            "..    ...  ...    ...   ...        ...            ...           ...\n",
            "145   6.7  3.0    5.2   2.3          0              0             1\n",
            "146   6.3  2.5    5.0   1.9          0              0             1\n",
            "147   6.5  3.0    5.2   2.0          0              0             1\n",
            "148   6.2  3.4    5.4   2.3          0              0             1\n",
            "149   5.9  3.0    5.1   1.8          0              0             1\n",
            "\n",
            "[150 rows x 7 columns]\n",
            "(150, 4) (150, 3)\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9474 - accuracy: 0.3733\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9397 - accuracy: 0.3867\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.9316 - accuracy: 0.3867\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.9246 - accuracy: 0.3733\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9163 - accuracy: 0.3867\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9098 - accuracy: 0.3867\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9017 - accuracy: 0.3867\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8954 - accuracy: 0.3800\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8885 - accuracy: 0.4000\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8809 - accuracy: 0.4200\n",
            "[[0.38148564 0.47679195 0.14172241]\n",
            " [0.3379552  0.49346182 0.16858305]\n",
            " [0.3829786  0.4568561  0.16016534]\n",
            " [0.38914108 0.44323757 0.16762133]\n",
            " [0.40707803 0.4549785  0.13794352]]\n",
            "   품종_setosa  품종_versicolor  품종_virginica\n",
            "0          1              0             0\n",
            "1          1              0             0\n",
            "2          1              0             0\n",
            "3          1              0             0\n",
            "4          1              0             0\n",
            "[array([[-0.20974535,  0.36637685,  0.02607175],\n",
            "       [ 0.5106693 , -0.03082958, -0.17309351],\n",
            "       [ 0.453219  ,  0.23940195,  0.376935  ],\n",
            "       [ 0.2530155 ,  0.12156814,  1.1437614 ]], dtype=float32), array([ 0.1324054, -0.3619312,  0.2613537], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "#1. 과거 데이터 준비\n",
        "filepath='/content/iris.csv'\n",
        "iris=pd.read_csv(filepath)\n",
        "iris.head()\n",
        "\n",
        "#one-hot encoding\n",
        "after_encoding=pd.get_dummies(iris)\n",
        "after_encoding.head()\n",
        "print(after_encoding.columns)\n",
        "\n",
        "#독립변수, 종속변수\n",
        "independent=after_encoding[['꽃잎길이','꽃잎폭','꽃받침길이','꽃받침폭']]\n",
        "dependent=after_encoding[['품종_setosa','품종_versicolor','품종_virginica']]\n",
        "print(independent.shape,dependent.shape)\n",
        "\n",
        "#2.모델구조\n",
        "X=tf.keras.layers.Input(shape=[4])\n",
        "#H=tf.keras.layers.Dense(8,activation='swish')(X) #위에서 만든 히든레이어를 밑H에 집어넣음 밑에도 똑같이\n",
        "#H=tf.keras.layers.Dense(8,activation='swish')(X)\n",
        "#H=tf.keras.layers.Dense(8,activation='swish')(X)\n",
        "H=tf.keras.layers.Dense(8)(X)\n",
        "H=tf.keras.layers.BatchNormalization()(H)\n",
        "H=tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "H=tf.keras.layers.Dense(8)(X)\n",
        "H=tf.keras.layers.BatchNormalization()(H)\n",
        "H=tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "H=tf.keras.layers.Dense(8)(X)\n",
        "H=tf.keras.layers.BatchNormalization()(H)\n",
        "H=tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "Y=tf.keras.layers.Dense(3,activation='softmax')(H)\n",
        "model=tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "#모델 구조 확인\n",
        "model.summary()\n",
        "\n",
        "#3.모델 학습(FIT)\n",
        "model.fit(independent,dependent,epochs=100,verbose=0)\n",
        "\n",
        "#모델 이용, 맨 처음 데이터 5개\n",
        "print(model.predict(independent[:5]))\n",
        "print(dependent[:5])\n",
        "\n",
        "#wigths&bias 출력\n",
        "print(model.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy3jk52uzXG3",
        "outputId": "6fc75e81-994b-4273-b057-eb2da9125532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭', '품종_setosa', '품종_versicolor',\n",
            "       '품종_virginica'],\n",
            "      dtype='object')\n",
            "(150, 4) (150, 3)\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 4)]               0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 8)                 40        \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 99\n",
            "Trainable params: 83\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "[[9.9683857e-01 3.0969286e-03 6.4478008e-05]\n",
            " [9.8283160e-01 1.7035002e-02 1.3343977e-04]\n",
            " [9.9379373e-01 6.1406689e-03 6.5588349e-05]\n",
            " [9.8847198e-01 1.1400403e-02 1.2758297e-04]\n",
            " [9.9776721e-01 2.1809547e-03 5.1840441e-05]]\n",
            "   품종_setosa  품종_versicolor  품종_virginica\n",
            "0          1              0             0\n",
            "1          1              0             0\n",
            "2          1              0             0\n",
            "3          1              0             0\n",
            "4          1              0             0\n",
            "[array([[-0.43390095,  0.08045479, -0.3150978 , -0.14467534, -0.15508305,\n",
            "         0.20257959, -0.32522553, -0.0244522 ],\n",
            "       [ 0.63528657, -0.1081973 ,  0.53620034,  0.6324112 , -0.06036162,\n",
            "         0.06441642, -0.4794865 , -0.75458497],\n",
            "       [-0.25855628,  0.2772202 , -0.87382185, -0.09023225,  0.33726725,\n",
            "        -0.21859251, -0.21051565, -0.09510653],\n",
            "       [-0.12343647,  0.5915608 , -0.10492878, -0.53498214, -0.53279734,\n",
            "        -0.1263513 , -0.40991962,  0.02979505]], dtype=float32), array([-1.4954415e-04,  1.5446675e-03, -6.1814778e-04, -2.6095812e-03,\n",
            "       -1.1979081e-03, -1.7484582e-03,  1.1814749e-05, -9.1166608e-04],\n",
            "      dtype=float32), array([1.232824 , 1.4135711, 1.3506259, 1.4408884, 1.3366005, 1.2211182,\n",
            "       1.2732997, 1.154836 ], dtype=float32), array([-0.02238824,  0.18675007,  0.31982857, -0.11881471,  0.4587651 ,\n",
            "        0.16525237,  0.29524443,  0.2613732 ], dtype=float32), array([-1.6524639 ,  2.2915587 , -3.5196078 ,  0.43230388, -0.20159228,\n",
            "        0.32656795, -4.901657  , -2.7574935 ], dtype=float32), array([0.79933107, 1.2137604 , 3.2376695 , 0.52056956, 0.04560776,\n",
            "       0.14634424, 0.746076  , 0.09596211], dtype=float32), array([[ 0.6259071 ,  0.11339653,  0.09142476],\n",
            "       [-0.99970317, -0.67863953,  0.3121159 ],\n",
            "       [ 1.0161428 ,  0.21644902, -0.5305813 ],\n",
            "       [ 0.80448794, -0.39708987,  0.11155722],\n",
            "       [-0.5834165 ,  0.26664498,  0.11435671],\n",
            "       [ 0.88054127,  0.04405591, -0.59575456],\n",
            "       [ 0.07952907, -0.31089586, -1.0313691 ],\n",
            "       [-0.05278047,  0.69618344,  0.06600512]], dtype=float32), array([-0.35578462,  0.28343546, -0.06006925], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "#기본적인 인공 신경망은 레이어가 순차적임. 이때 사용할 수 있는 함수가 케라스의 모델 도구 Sequential임.\n",
        "from tensorflow.keras.layers import Dense,Activation\n",
        "#레이어 도구 중 Dense 와 Activation도구를 불러오는 명령어. Dense는 각 레이어의 뉴런의 개수를 설정, Activation은 활성화 함수의 의미\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#유틸도구 중 to_categorical 함수를 불러오는 명령어.원-핫 인코딩을 구현할 수 있는 함수임.\n",
        "from tensorflow.keras.datasets import mnist\n",
        "#케라스를 사용해 딥러닝 모델 개발연습을 할 수 있는 데이터가 있고, 그 데이터는 데이터셋 도구에 있어 mnist 데이터셋을 불러옴.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "PRYJmQ1Z91LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#숫자 맞추기\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense,Activation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#학습을위한데이터  학습이 잘되었는지 검증하는데이터 x는 손글씨의 의미\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data() #어떤거를 검증용으로 쓸지 train/test data가 알아서 나뉨.\n",
        "print(\"x_train shape\",x_train.shape)\n",
        "print(\"y_train shape\",y_train.shape) #-> x=독립변수, y=종속변수\n",
        "print(\"x_test shape\",x_test.shape)\n",
        "print(\"y_test shape\",y_test.shape)\n",
        "\n",
        "#결과분석: 괄호안에있는 숫자들\n",
        "#x_train의 60000은 내가 트레이닝 시켜야할 글씨는 6만개라는 뜻이고 그 옆 28,28은 정사각형 한 칸의 넓이(?)가 28x28이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cemhCDKm-nlI",
        "outputId": "ad9be2b7-0541-49df-ee15-e688b51a5792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "x_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense,Activation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "print('before x_train shape',x_train.shape)\n",
        "print(\"before x_test shape\",x_test.shape)\n",
        "\n",
        "X_train=x_train.reshape(60000,784) #아까는 28,28인것을 1x784로 바꿔라는 뜻.\n",
        "X_test=x_test.reshape(10000,784)\n",
        "X_train=X_train.astype('float32') #astype은 타입을 바꾸는 함수\n",
        "X_test=X_test.astype('float32')\n",
        "X_train/=255 #255로 나눈다는 뜻.\n",
        "X_test/=255\n",
        "print(\"after X Training matrix shape\",X_train.shape)\n",
        "print(\"after X Testing matrix shape\",X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ly41kBQJI3x",
        "outputId": "2e256173-ae23-4696-a170-fe7a8deda60a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before x_train shape (60000, 28, 28)\n",
            "before x_test shape (10000, 28, 28)\n",
            "after X Training matrix shape (60000, 784)\n",
            "after X Testing matrix shape (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "print('before x_train shape',x_train.shape)\n",
        "print(\"before x_test shape\",x_test.shape)\n",
        "\n",
        "X_train=x_train.reshape(60000,784)\n",
        "X_test=x_test.reshape(10000,784)\n",
        "X_train=X_train.astype('float32')\n",
        "X_test=X_test.astype('float32')\n",
        "X_train/=255\n",
        "X_test/=255\n",
        "print(\"after X Training matrix shape\",X_train.shape)\n",
        "print(\"after X Testing matrix shape\",X_test.shape)\n",
        "\n",
        "Y_train=to_categorical(y_train,10)#예측이 아닌 분류문제에서 대부분 정답 레이블을 1,2,3번째와같이 순서로 나타내도록\n",
        "Y_test=to_categorical(y_test,10)  #데이터의 형태를 바꾸기 위하여 one-hot encoding을 사용함.\n",
        "print(\"after one-hot encoding Y Training matrix shape\",Y_train.shape)\n",
        "print(\"after one-hot encoding Y Testing matrix shape\",Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aczgjDhKrYq",
        "outputId": "8b49a5e9-e6e0-47e9-e443-c8713015f329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before x_train shape (60000, 28, 28)\n",
            "before x_test shape (10000, 28, 28)\n",
            "after X Training matrix shape (60000, 784)\n",
            "after X Testing matrix shape (10000, 784)\n",
            "after one-hot encoding Y Training matrix shape (60000, 10)\n",
            "after one-hot encoding Y Testing matrix shape (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(512,input_shape=(784,))) #모델에 층을 추가한다.\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnFPhdWsHjAd",
        "outputId": "3263c3fd-048a-4319-acab-d5c8678f3f5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,batch_size=128,epochs=10,verbose=0)\n",
        "\n",
        "score=model.evaluate(X_test,Y_test) #evaluate함수는 모델의 정확도를 평가할 수 있는 기능을 제공\n",
        "print('Test score:',score[0]) #score[0]은 오차값\n",
        "print('Test accuracy',score[1]) #score[1]은 정확도"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge1cpQKPJPs1",
        "outputId": "4b802b82-4e08-471d-aa39-406ffac131c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0770 - accuracy: 0.9818\n",
            "Test score: 0.07702967524528503\n",
            "Test accuracy 0.9818000197410583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a=np.array([1,0,2,3,0])\n",
        "print(np.nonzero(a)) #0이 아닌 인덱스를 찾아냄 리스트의 숫자가아닌 순서의 숫자를 보여줌.(0,1,2,3 순에 있는 번호 보여줌.)\n",
        "print(np.nonzero(a)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kacn8KCAPAfs",
        "outputId": "37e0119d-5069-4a9e-87d3-1ed1940ef8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 2, 3]),)\n",
            "[0 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes=np.argmax(model.predict(X_test),axis=1)\n",
        "correct_indices=np.nonzero(predicted_classes==y_test)[0]\n",
        "incorrect_indices=np.nonzero(predicted_classes !=y_test)[0]"
      ],
      "metadata": {
        "id": "amHbPkasTa0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#인공지능이 잘 구분한 그림\n",
        "plt.figure()\n",
        "for i,correct in enumerate(correct_indices[:16]):\n",
        "  plt.subplot(4,4,i+1) #4,4는 밑에 표의 4x4라는 뜻. \n",
        "  plt.imshow(X_test[correct].reshape(28,28),cmap='gray',interpolation='none')\n",
        "  plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct],y_test[correct]))\n",
        "plt.tight_layout()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "6mvcZxHSSCOk",
        "outputId": "ab6bb733-93f1-4569-eb1d-2c6db88b5d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAEYCAYAAAAkik0PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeZgU1dX/PwcYkE12lB1lBBXigoiIqGBQUcAVXKIx6OuW1y1qVFSi/ETUxN28AmLENYpGcSeiBk0kiIoIKCIEEQRk3xcJM93n98e9M9QM0z09Mz3d1d3n8zz1TE/d7dz61rn31q1bVaKqGIZhGEYuUiPdBhiGYRhGurBO0DAMw8hZrBM0DMMwchbrBA3DMIycxTpBwzAMI2exTtAwDMPIWdLaCYrIMyJyt/99rIgsSFG5KiL5qSirVLkdfdm1Ul12ZTGNMgPTKfzkoEZ9RWR5qsutKOV2giKyRER+FpFtIrLaC9kg2Yao6ieq2iUBe4aJyLRklx/If56va9FWKCJvVyB9ZxH5m4isE5HNIjJXRG4QkZrVaHOZGonI30vVZZeIfF3ZckKk0QMi8h8R2Soi34nIRRVMn3KNfLll6XS7iHzj6/KDiNxU1XJCpNM5IjJdRHaIyMeVSB8mX+onIh95O5ZUtZwQaVRHRCaIyBYRWSUiN1QwfU8RmSwim0Rkg4h8LiIXV5e95dhSqbokeiU4WFUbAN2BHsCIMgzImBFZPFS1q6o28PVtCCwD/pZIWhHpBHzm0/xCVRsBQ3HHrGE1mVzEHhqp6ilFdfFhn5JgXULOdmAw0Aj4DfCoiPROJGGaNYI9deoPXAQ0AQYAV4vIr1JgRyrYADwC3FfRhGHzJdw5NwG4yduXFe0dMBI4AOgA9ANuFpEBiSQUkaOBqcA/gXygGfBb4JRqsbR8RlKZuqhq3A1YAvQP/H8/8I7/rcBVwH+AH/y+QcBsYBMwHTgkkPZwYBawFXgZmAjc7cP6AssDcdsBk4C1wHrg/4CDgJ1ABNgGbPJx6wAPAD8Cq4FxQN1AXjcBK4GfgEu83fkJ1P14b2v98uL6+C8A78YJ7+jLruX/vxiY78tYDFwRiNsceMcfxw3AJ0ANH3YLsMKnWwCsSkCjH/zvjtmkkU/7FnBjyDX6JYn50iZgczb5EnAp8HEi+oRAp/J86TGggCxp73yckwL/jwImJqjRNODxOOGl6zgc+N4fj2+BMwNh+bjOdDOwDnjZ7xfgYWANsAX4GuiWzLpUqBP0Qs0DRgVOig+ApkBdL/oa4CigJm6UvsSLVhtYClwP5AFD/Mm0x0nh087xla8P7AX08WHDgGmlbHwY1xA2xY0S3wbu9WED/InSzef1YryTolS+E4BnKuC4q4CLK+C4A4FOXujjgR1Adx92rz+58/x2rI/XBTc6bh3Ic3kCGt0L/CsLNaqLc/gBIdeoE4n50lzgmmzSicp1gmH1pS9xnU/Gt3e42QcF9gnsGwJ8nYA+9XCdc784cYrr6P8fCrTGzUCei7u6buXDXgJu92HB+p/sj3ljr9lBRWmSVpcEKrsEPwrxoo7Bjzp8oScE4o4tOmEC+xbgTsrjcD21BMKmxzgpjsaNiGqVYU+Jk8IfmO1Ap8C+o9k9UpsA3BcI6xzrpChD5C1A3wo4bgFxGmNKOW4Z4W8A1/nfdwFvlrYTN2Jag5tGy0tUI2CRP3ZZo5GP+yzwXtDmMGqUoE7P4hrDOtmkE5XrBMPqS78Hlvj/M1ojXCevwF6BfScW1a8cfdr4tAfGiVNcxxjhs4HT/e/ngPFA21JxTgAWAr3wV+8x8qp0XRK9J3iGqjZW1Q6q+r+q+nMgbFngdwfgRn+TdJOIbPLGtfbbCvXWeZbGKK8dsFRVCxOwrQWuw/oyUOZ7fj++3KCNscoszVm4qZN/Jhgf3DRGq0Qji8gpIjLD31DeBJyKm7oBNw2zCHhfRBaLyHAAVV0E/A43/71GRCbiRpLxNGoJ7Au8ShZpJCL340a855SyOR5p0UhEWvs08XQ6ARioqv8li3SqJGH1pbWB35mu0Tb/d+/Avr1x05XlsRGIUjGNLhKR2QG7u7Fbo5txHfzn4hYnXgKgqlNxU8OP4zQaLyJ7l5F9peuSjEckgiIvA0b7E6hoq6eqL+GmrNqIiATit4+R5zKgfYybz6Ubu3XAz0DXQJmN1N3YxpfbLoEyS/Mb4LkKNK4AHwJnJxJRROoAr+Hm9vdR1cbAZNyJgKpuVdUbVXV/4DTgBhH5pQ97UVX74JxQcVMB8TgTmKSq28gSjUTk/+FuwJ+kqlvKix8gXRr9MU45l/ifF6lq0ZLyrNCpCoTVl7KmvVPVjT7+oYHdh+KmgOOiqjtwC+0S1agD8CRwNdDMa/QNuzVapaqXqWpr4ApgjPjHOlT1MVU9AjgYd2W7xwrqqtQl2c8JPglcKSJHiaO+iAwUkYa4A1YIXCsieSJyFtAzRj6f4yp0n89jLxE5xoetBtqKSG0AVY36ch8WkZYAItJGRE728V8BhonIwSJSD7izvEqISFvc6qJnywhbIiLDYiS9E+gtIveLyL4+fr6IvCAijUvFrY2b9loLFIrIKcBJgXIG+bSCu1kcAaIi0kVETvCOvxPnEOVxKvCM/53xGonIrcCvcPdu1pcRHkaNojHqcgFwj/83OILPBp1qisheQC2ghi87LxAeRp1i1aWorazl/pW9gKfJcI1w05AjRKSJiBwIXMbutqLoGcO+MdLe7Mu6SUSa+fiHiruiLk19XIe+1se7GHclWFTOUN/ugrvKVJxGR/rjm4ebBt5JDF8qry4xKW++lFIr2kqF7THXjLsx+wVuTn0lbkl+Qx/WA/iK3aulXib2aqn2uHn99bjRz2N+f23gXdxU5Tq/by9cQ7IYdx9vPnBtIK/huBvtCa1oA24FPiljf21ve7x58C6+zutxDjcHN+VSkz1v5l+FO8k3Ac9TcvXY9f7Yb8fdrP+D338Izmm2+mPwDq7xjKfRCkrem8hojXzYf3FTIEXbbSHXqDVl+BJu1W6BL3O7r8u4LNFpmA8Pbs+EXKcyfckf09J1+TgLNKqDu4+4xR+/GwJh7fz+ZnE06gn83euzAfdYy0Ux6ji6qB7AQ7hbTZf6sD/h2qltuBWkl/v9v8QtFtvm0/0VaFDRusTbxCc2EkBE+gBXqer56bbFKBvTKDMwncKPiFyIm3a9Nd22VCfWCRqGYRg5i71A2zAMw8hZMqYTFJEBIrJARBaJX+JshA/TKfyYRuHHNEodGTEdKu6FuQtxDz8ux92IPl9Vv02rYUYJTKfwYxqFH9MotWTKS2B7AotUdTGAX4J7Ou79c2UiIinp3VVVyo+VM1RIp1RphFtV16L8aDmBaRR+rL1LIZkyHdqGks9QLff7SiAil4vITBGZmTLLjCDl6pQmjarzzSaZhmkUfqy9SyGZciWYEKo6Hvf+uVSOYI0KYBqFH9MoMzCdkkOmdIIrKPkqoLZ+nxEukq7T73//e+rWrcshhxzCkCFDABg7diyffvopzz//fFWyzlXMl8KPaZRKEnmiPt0brrNeDOyHe4PCHNxDnPHSlH67Q7Vs6T42YdoqqlN5x/bll1/WSCRS5rZw4UJt3759ojrNTPexCcuWbI3ibZ07d9ZoNKrXXHONaVSNGlVUp/r16+uYMWM0Eono559/rh06dMjp9i4j7gmqe7v61cAU3CuCXlHVcl+MaqSWZOr08ssvF1/5AXz33Xc8+uijvP322wB06tSJCy64oOpG5xip9KXDDz+caDTK8uXLy49sFFPdGrVq1YrLLruMaDTKEUccwaBBg5KVdWaS7l64GkdTZY5kpkyZok8//bSOHTtW+/Tpo/n5+XYlGDKNBg8erAUFBTp37lxt1apVibBbb71Vd+7cqZFIRPv162dXgmnSqLytW7duunXrVh0zZoxpFBKdrr32Wp06daoWFBQUb5FIRF9++WW95ppr9LjjjsvJ9i4jnhOsDLFuFEejJV9AvnXrVubNiz/Iuvbaa5k5s+wFWJqFS4ZTRbyb+R06dGDr1q1s2LChxP45c+bQrZt7+Xz//v356KOPEinqS1XtURVbc5XKLrgYMmQIr7zyCv369eOf/0zok5ymURVIRKdIJLJH+1ejRo3ifUuXLuXcc8/lyy+/jJlHNrZ3mbIwJmnceOONzJ8/n4MOOoju3bvTt29fevXqxbJly2jXbve96MLCQtauXUurVq0477zzYnaCRvWwdOmeK+ZvuukmOnfuDMBnn33GZ599lmqzjAS5+eabWbp0qflNSJg8eTI1aux592v9+vVs27aNDh06sN9++/H5559Ts2bNNFiYPnKuE3z44YcBeO+99wBo0qQJhx12GF9++SVHHnlkcbydO3eycOFC5s+fz/fff58WW43dDBo0iLvuuovatWuzZs0abr31Vnbs2JFus4wy6NixIz169GDhwoVs37493ebkPMcffzxdunQhGo2WuBIcN24c77//Pps3b+aEE07g9ttvT6OVaSTd87HpnCMvbzv77LM1Eolo06ZNc2qOPIwajRw5snhl6COPPFJRLe1+Uwo0Ktp+85vfaDQa1U8++cQ0SrNOHTt21JUrVxbf/ysoKNBFixbpH//4R61Xr15xvA4dOuhPP/2kBQUFev3112teXl7OtHdpNyDVJ0WiW8uWLXX16tWqLjPrBNOo0RtvvKE7duzQSCSiTz/9tDZo0MA6wZBpFNweeOABjUajOnjwYNMozTrl5+eXWATz4YcfavPmzcuMe8011xTH7dSpU860dxnxiEQ6uOqqq2jRogUbN25Mtyk5TatWrejduzd16tRh3bp13H333Wzbti3dZhkx6NWrFxdffDFfffUVH3zwQbrNMQLMnDmTSy65hHXr1pUZ/tZbb8VdFJOtWCdYBscccwzDh7uvl5xxxhlptia3ee2112jWrBkAL7zwgt2fDTn9+/enadOmfPfdd+zcuTPd5hi4FaA1atTgqKOO4scff4wZT0SK444cOTJ1BqaZnFsYkwinnnoqeXl5/OMf/+DTTz9Ntzk5y2mnnUb37t0B+Pjjj7nzzjvTbJFRHoceeiiqyquvvppuUwzgyiuv3OOxiFgMHjy4+AUH1gnmMHXr1mXAgAHs2rWLO++8k4KCgnSblJM0a9aM2267jby8PABmz55t06AhZ9999+XYY49lwYIFvP766+k2x8B1bOXRokULDj74YG677TYA1q5dm1Ptnk2HluKmm27i8MMPZ+rUqUyfPj3d5uQsN954Y/EjK2+88YZdBWYAw4YNo2XLlsyYMSPdphgV4Pbbb+fDDz+kefPmAJxzzjlxp02zDbsSDDBw4ED+8Ic/sGXLFu666650m5PT3HDDDcW/r776arsKzAA6dOgAYIvJMojJkyfTpUuXEvumTZuWJmvSg3WCnmbNmvHYY49Rs2ZNJk+ebKPZENG0adM9pmc2b95MQUEBeXl5NGrUiMaNG5foOCORCLfccos9UJ9Cil7EXPSScyP9FC12ATjllFMAGD9+PK1btwZKvjYtV7FOEOjcuTPfffcdAKeffro5cQiYPHkyp59+OgBz584tN/6uXbsAt8y76FVdhxxyiA1mUsSDDz5ImzZt+Oqrr/jXv/6VbnMMz4knnsinn35KixYteOedd4o7vGDHt3r1aubPn8/ll1/OypUr02Vq2ghVJygi7YDngH1wD2eOV9VHRWQkcBmw1ke9TVUnJ6PMDh068P777wPufuA777yTjGyzllRpdNZZZ3HzzTcXL4wB6Nq1K+eee27x/xMmTGDJkiUAjB49urJFZR2p9qN69epx6qmnAvDqq68SiUSqmmVOkAqdli5dynnnnccZZ5zBddddV2ac0aNH8/jjj1cm++wg3U/rl3rrQSugu//dEFgIHAyMBH6fjDcolN5Gjx6t0WhUo9Go9ujRo8Jvx0j3McsFjZKw5dTbSFKtUV5enk6fPl3feOONEq/iMo3CpdOAAQN00qRJWlBQoK+99pqefPLJOmDAgIp8nFrTfcyqYwvVlaCqrgRW+t9bRWQ+0Ka6yuvTpw/XXHNNdWWflaRaI6PipFqjgoICevfuXV3ZZy2p1um9994r/nCAsZvQPiIhIh2Bw4Gi7+VcLSJzRWSCiDRJRhnHHnssDRo0AOD777+3FYgVJBUaGVXDNMoMTKf0EcpOUEQaAK8Bv1PVLcBYoBNwGG7k9GCMdJeLyEwRqdBHzObMmcNRRx1VvDjGKJ9Ua2RUHNMoMzCd0kvoviwvInnAO8AUVX2ojPCOwDuq2q2cfFJSMc3CLy2XR6ZpRA5+tdw0ygwyTadsbO9CdU9QRAR4CpgfPCFEpJWfPwc4E/gmgey2AQuSbyUAzYF1QIdqyj+0JFmjdcB2/zfZFGkEOaZTBmkE5kvW3qWZUF0Jikgf4BPga6DoQZbbgPNxUwMKLAGuCJwksfKaWV0jy+rMO+wkUyOfX7UcS9Mo/BpVd95hx9q7cBCqK0FVnQaUdbmdlGcCjapjGoUf0ygzMJ3CQSgXxhiGYRhGKsjmTnB8huada1TXsTSNkof5UvgxjSpJqO4JGoZhGEYqyeYrQcMwDMOIi3WChmEYRs6SlZ2giAwQkQUiskhEhlchn3Yi8pGIfCsi80TkOr9/pIisEJHZfjs1edbnBsnSyOdlOlUDplFmYO1d1ci6e4IiUhP3NvYTgeXAF8D5qvptJfJqBbRS1Vki0hD4EjgDOAfYpqoPJM/y3CGZGvn8TKckYxplBtbeVZ1svBLsCSxS1cWquguYCJxemYxUdaWqzvK/twL2xYTkkDSNwHSqJkyjzMDauyqSjZ1gG2BZ4P/lJEFIe8t7UqkWjcB0SiKmUWZg7V0VycZOMOlU9i3vRmoxncKPaRR+ck2jbOwEVwDtAv+39fsqhX/L+2vAX1V1EoCqrlbViKpGgSdxUxJG4iRVIzCdqgHTKDOw9q6KZGMn+AVwgIjsJyK1gfOAtyqTUby3vAeiJfqWd2M3SdMITKdqwjTKDKy9qyKheoF2MlDVQhG5GpgC1AQmqOq8SmZ3DPBr4GsRme333QacLyIl3vJeNatziyRrBKZT0jGNMgNr76pO1j0iYRiGYRiJko3ToYZhGIaRENYJGoZhGDmLdYKGYRhGzmKdoGEYhpGzWCdoGIZh5CzWCRqGYRg5i3WChmEYRs5inaBhGIaRs1gnaBiGYeQs1gkahmEYOYt1goZhGEbOYp2gYRiGkbOktRMUkWdE5G7/+1gRWZCiclVE8lNRVqly+4rI8lSXWxVyUKOOvuyM+sJKDupkvpR4ueZLcSi3ExSRJSLys4hsE5HVXsgGyTZEVT9R1S4J2DNMRKYlu/wyymkqImsrWpaI9BSRySKySUQ2iMjnInJxddnpy4yrUWXrUpqwaCQi54jIdBHZISIfVyJ9ZxH5m4isE5HNIjJXRG4QkZrVYG6w3LJ0OkVEPvJ2LElGOWHRKVCO+VIpwqKRiLQRkTf98V0uIldWMH1afCmGLY1F5FkRWeO3kYmkS/RKcLCqNgC6Az2AEWUYEOrevhL8EZhfkQQicjQwFfgnkA80A34LnJJ06/YknkYVrkvI2QA8AtxX0YQi0gn4DFgG/EJVGwFDccesYTKNjEFpnc4DJgA3BWw0XzJfShUvAD8A+wADgXtEpF8iCUPgS6V5GKgHdAR6Ar9OaNCkqnE33EcU+wf+vx94x/9W4CrgP8APft8gYDawCZgOHBJIezgwC9gKvAxMBO72YX2B5YG47YBJwFpgPfB/wEHATiACbAM2+bh1gAeAH4HVwDigbiCvm4CVwE/AJd7u/Dh17g18ClwMTCvvGAXSTQMejxNeuo7Dge/98fgWODMQlo9rADYD64CX/X7xYq8BtgBfAyvK0WixPy47s0Ujn+ZS4ONE9fFpXgDejRPe0Zddy/9/Ma7R2+qP4xWBuM2Bd/xx3AB8AtTwYbd4XbYCC4BfUr4vrcd8yXwpRRoBDXxYi8C+8cDzYfelGOWtA44M/H8b8Em59UigokuKTgov1DxgVOCk+ABoCtT1oq8BjsJ95fg3Pn0doDawFLgeyAOGAAVlnRQ+7RzcCVof2Avo48OGUcqZfLy3vB0NgbeBe33YAH+idPN5vRjrpAiUPQs4oqyy4hynev5k7VcBxx0KtMZdkZ8LbAda+bCXgNt9WLD+JwNfAo1xTnwQbiS2h0a+LgrMwA1WpmeDRoE8K9MJrgIuroDjDgQ6+WN9PLAD6O7D7sU1QHl+O9bH6+I1aR3IsxPl+9LPmC+B+VJKNPJpFWgZ2Pck8FXYfSlGeeuAnoH/bwc2lluPBCq6BD8K8aKOwY86fAVPCMQdi3fqwL4FvsLH4UYmEgibHuOkOBo3IqpVhj0lTgp/oLYHD4xP/4P/PQG4LxDWOdZJ4cOvB8bGOgHjHKc2Pt8DE3XcMsJnA6f738/hRmVtS8U5AVgI9GL3SKlMjXxd1KcZhhtdZ7xGgXiV6QQLgAGJOm4Z4W8A1/nfdwFvlrYTd+WxBugP5FXAl1aZL5kvpVijacCfcR1vd9xV2IKw+1KM/F7AXU039Om+B/5bXj0SvSd4hqo2VtUOqvq/qvpzIGxZ4HcH4EZ/I3uTiGzCjaZa+22Fems9S2OU1w5YqqqFCdjWAjdy/DJQ5nt+P77coI2xykREWgPX4kYQFWUjEAVaJZpARC4SkdkBu7vhpgUAbsad8J+LyDwRuQRAVafipkoeB9aIyHgfr4RGQBNfF8gijZLAeiqm0SkiMsMvHNgEnMpuje4HFgHvi8hiERkOoKqLgN8BI3EaTfTnFsT3peCxzGidzJfCr5HnAmA/n2YsriNJdNVtun2pNNfiZlP+g+tQX0qkLsl4RCIo8jJgtD+BirZ6qvoSbo66jYhIIH77GHkuA9rHWCCgpf5fh6t410CZjdTd2MaX2y6BMsHdTG0FfCsiq4BHgZ4isqq81U6qugN37+PsePGKEJEOuKmHq4FmqtoY+AbnhKjqKlW9TFVbA1cAY8Qvc1bVx1T1COBg3EivUZy6gBuBPur39QXuyWCNqsqHJK5RHeA13P2XfbxGk9mt0VZVvVFV9wdOA24QkV/6sBdVtQ+uoVTcgoqKYL5kvgTV7EuqulRVB6lqC1U9CtcpfR4vTYBQ+ZKqblDVC1R1X1Xtiuvfyq1Lsp8TfBK4UkSOEkd9ERkoIg1xJ3UhcK2I5InIWbgTqSw+x4l5n89jLxE5xoetBtqKSG0AVY36ch8WkZZQvOz3ZB//FWCYiBwsIvWAO+PY/3fcJfxhfrsD+Ao4TFUjPm8Vkb4x0t/sy7pJRJr5+IeKyMQy4tbHCbrWx7sYN3rF/z9URNr6fzf6uFEROdIf3zzctMjOcuoCMDhQlzOBKzJYI0SkpojsBdQCaviy8wLhS0RkWIzkdwK9ReR+EdnXx88XkRdEpHGpuLVx93fWAoUicgpwUqCcQT6t4BZdRHAadRGRE7zj78Q1WtEYdanh6+L/lb38cTNfMl+C6velg0SkoYjUFpELcef3Q4HwTPKlTiLSzLcPpwCXA3fHqz8kuRNU1ZnAZbgpho24y9thPmwXcJb/fwPu5vWkGPlEcCdbPm4F1HIfH9yy6XnAKhFZ5/fd4suaISJbcCOULj6vv+OW00/1cabGsf+/ftS4SlVX4cQo8L8RkXa4FUpfx0g/HXfP4ARgsYhswN2LmFxG3G+BB3HOshr4BfDvQJQjgc9EZBvuJvh1qroY2BvnBBtxUx3rvZ1l1sX/uy5QlylksEaeX+OcYSzuBvrP/pjgG4tmuAUMZdn9Pe4eSkdgnohsxo1QZ+K0DcbdiptieQV3rH6F06KIA3w9tuF0HKOqH+Gc/T7ccV8FtARujVGX47z94KayfgbeN18yX/LB1e1LJ+NWam4ErsTd4ysaTGSaLx2BO5+24hbaXKCq88qpv7tpaySGHyl1VdVYIhhpRkT6AFep6vnptsWIjflS+MkVX7JO0DAMw8hZMuYF2iIyQEQWiMgi8SuHjPBhOoUf0yj8mEapIyOuBMWtJlsInIibL/8CON/fCzBCgukUfkyj8GMapZZMuRLsCSxS1cX+hvNE4PQ022TsiekUfkyj8GMapZBMeVFvG0o+ALoc96qiEojI5bhlseBWClU7qirlx8oZytUpHRoB61S1RfnRcgLTKPxYe5dCMqUTTAhVHY9bRo2IhH+eNwdJk0bV+QaarMM0ygysvUsOmTIduoKSb0Fo6/cZ4cJ0Cj+mUfgxjVJIpnSCXwAHiMh+/gHO8yj5oKURDkyn8GMahR/TKIVkRCeo7sWyVwNTcN+jeiWRNwGUR/fu3VmyZEncOCeddFLccGM31aVTWQwePBhV5aqrrqJmzZR/xDpjSbZGLVu25OOPP+aee+6hY8eOceM2atSIwYMHk5eXFzderpNKPzIo/1NKmbrh3g8Yc6tVq5Z+8sknunLlyrjxhg0bpvXr148Znu56ZvJWnkaxtjPPPFOLePHFF9XfD4m3zUx3XTN1i3VMmzdvrv/4xz80Eonon//854R0i0Qieumll5pGKdQpuF1wwQW6ZMkSjUQiGolEtFmzZhX2vXTXszq2jLgSrA769evH0UcfzdNPPx03XpMmTahXr16KrDLKo06dOtx+++6v8zz//PNFjYCRQrp3707fvn0BuOuuu8qN37VrV9544w1efvnlarbMKIu2bdvyyCOP0L797o9K/PnPf6Zp06ZptCokpLsXTsfIqFu3brpu3TpdsGCBNmjQIO7I5+OPP9YWLVrk1MgoDBrF2nr06KFFFBQUJJrOrjKSrNETTzyhkUhEhw0bVu7x79q1q65cuVIvvPBC0yjFOhVtjzzyiEYiEY1Go8VXgpFIRDds2KA33nij1q5dO2evBNNuQDpOiokTJ+rPP/+sPXr0iCt406ZNVVWtE0yDRrG2e++9V4t49913rRNMk0aqqjNnzox7q6Bou/LKKzUajZpGadAJ0A4dOujmzZs1Eono7NmzdcqUKSU6wpUrV+q+++6bs51gzk2HDhkyhFNPPZVFixYxc+bMuHFvv/12otEomzZtSpF1Rnkcd9xxAOzatavEtKiRWqLRKD/99BO7du2KGadu3bqMGjWK0aNHFzXURho47LDDaNiwIW6Ba9cAACAASURBVNOmTeOwww7j9NNP59JLL2Xx4sWICPvuuy9vvvlmzk6NZtXD8okwdOhQ6tWrx5gxY+LG69ixIxdccAGRSISCgoIUWWfEo3fv3vTu3RuA7du3M3v27DRblNsMHDiQ999/n02bNjF27NgSYccffzx9+/alV69eALz66qvpMNHA3UdXVR5++GEAdu7cydNPP83QoUPZf//9AdixY0fcAU02k3OdYJFTlnba0lx++eU0b96c+fPnp8IsIwGOPPLI4t/l6WdULz/99BOtW7fmuOOOQ0Q47bTTSoSLSPHV3+LFi7ntttvSYaYBnH+++xzgwIEDeeONN4r39+jRo/j3jBkz2LZtW8ptCwM5Nx3apk0bXnrppXLjderUCYBvvvmmuk0yEqTIacu68jBSyyGHHEL//v154IEHAFi7di0PPPBA8XbIIYcUx50+fTrff/99ukzNeYrauyOPPJIDDzyQoUOH8uKLL9KkSZPiWz2XXXYZBx98cDrNTB/pvimZ6hvFM2fO1Dlz5mjTpk1j3vxt2bJl8U3jq666KuduFKdbo7K2Pn36aCQSUVXVJUuWVHRBjS26SIFGwW3//ffXaDSqs2bNiruwzDSqfp2aNm2qGzZs2GN16JQpUzQ/P1+/++47jUQiOm7cuJxcGJNz06Hff/89Z599Nu+++y4PPfRQibBu3bqx//7707Fjx6ITi2g0mg4zjVI0a9aMGjXcxMUHH3yQZmuM8rjjjjtQVW655RbWrl2bbnNymg0bNnDOOefw6quv0qhRI8A9I3jLLbewc+dOJk2axPDhwzn55JPp1KlT7l21p7sXTvXI6MADD9RXXnlFt2/froWFhSW2VatW6cqVK7WgoKB4X926dXNuZJRujcrann/+eVVV3bhxY7mPtpSx2VVGCjQq2oYOHarRaFQ3b96s3bt3N41ColP//v11woQJ+tBDD5V4Prpu3br6+uuvayQS0WeffTbn2ruM+LJ8ZSjv0yKHHXYY+fn5JfYVrWB79tlnueCCCwCoVSv+xbJm4fe1UkWin39p27YtS5cupUaNGnzzzTf84he/qGhRX6pqj/KjGaWpzCd6JkyYwLBhw3jppZeK/SgBTKMqUNVPKZ133nn89a9/ZcWKFSXeKlOabGzvcm46tIjZs2fHXGK/ePHi4t/dunWzxTFppnfv3sVTocHVbUY4OeWUU9i+fTsPPvhguk0xEuSVV17htNNO49xzz023KSkn51aHVhTrANPPr371KwBmzZqV0HsqjfQxe/ZsWrZsySuvvMKsWbNo2LBh3CsLIxxEo1F+9atfcfPNN/Pqq69St27ddJuUMqwTLIO99toLgJ9//jnNlhh5eXnFj6vs3LnTXlyQIUQiES644AI++ugjRo0alW5zjAR57rnnOOusszjggAPSbUrKCFUnKCLtROQjEflWROaJyHV+/0gRWSEis/12anXacfHFF7Np0yZGjBhRncVkJKnWKBqNFr/ebtGiRcnIMusJgx9deumlPPfcc8yaNcv8KAZh0Kk0RSt5b7nlllQVmX7SvTKn1AqnVkB3/7shsBA4GBgJ/D7Zq6VibW+//bb269cvobjpPma5oFHr1q11woQJ5T6zGWfLqZWH6fSjPn366NSpU3XkyJG6zz77JPx1glzTKN06xdvef/993bp1qx588ME50d6FamGMqq4EVvrfW0VkPtAm1XYMHjw41UVmDOnQ6KeffuKSSy6pziKyinT60bRp0zjhhBNSUVTGE5b2rjRDhgxhzpw55Ofn8+2336bbnGonVNOhQUSkI3A48JnfdbWIzBWRCSLSJEaay0VkpojE/zyEkRRMo/BjGmUGYdJpy5Yt7Lfffrz11lvJzDa0hPI5QRFpAPwTGK2qk0RkH2Ad7pJ8FNBKVeNeGlT1uZlE0Sx8biYRMkkjcvQZNNMoM8gknbKxvQtdJygiecA7wBRVfaiM8I7AO6rarZx8tgILqsNGoDnuJO2gqi2qqYzQkkSN1gLbcccy2RRpBDmoU4ZoBOZL1t6lmVDdExQRAZ4C5gdPCBFp5efPAc4EEnl4b0F1jSxFZGYOj1qTppGqtqiuY2kahV8jb5PpZO1dWglVJwgcA/wa+FpEil7nchtwvogchpseWAJckR7zDEyjTMA0ygxMpxAQqk5QVacBZc05T061LUbZmEbhxzTKDEyncBDa1aFJYHyG5p1rVNexNI2Sh/lS+DGNKknoFsYYhmEYRqrI5itBwzAMw4iLdYKGYRhGzpKVnaCIDBCRBSKySESGVyGf0L3gNltIlkY+L9OpGjCNMgNr76pG1t0TFJGauBfRnggsB74AzlfVCr8ET0Ra4d7WMEtEGgJfAmcA5wDbVPWB5FmeOyRTI5+f6ZRkTKPMwNq7qpONV4I9gUWqulhVdwETgdMrk5GqrlTVWf73ViAUL7jNApKmEZhO1YRplBlYe1dFsrETbAMsC/y/nCQIWZkX3BoxqRaNwHRKIqZRZmDtXRXJxk4w6fgX3L4G/E5VtwBjgU7AYbhPoTyYRvMMj+kUfkyj8JNrGmVjJ7gCaBf4v63fVyn8C25fA/6qqpMAVHW1qkZUNQo8iZuSMBInqRqB6VQNmEaZgbV3VSQbO8EvgANEZD8RqQ2cB1Tqw1jxXnAbiJboC26N3SRNIzCdqgnTKDOw9q6KhOrdoclAVQtF5GpgClATmKCq8yqZnb3gthpIskZgOiUd0ygzsPau6mTdIxKGYRiGkSjZOB1qGIZhGAlhnaBhGIaRs1gnaBiGYeQs1gkahmEYOYt1goZhGEbOYp2gYRiGkbNYJ2gYhmHkLNYJGoZhGDmLdYKGYRhGzmKdoGEYhpGzWCdoGIZh5CzWCRqGYRg5S1o7QRF5RkTu9r+PFZEFKSpXRSQ/FWWVKreviCxPdblVIQc16ujLzqgvrOSgTuZLiZdrvhSHcjtBEVkiIj+LyDYRWe2FbJBsQ1T1E1XtkoA9w0RkWrLLD+T/jIjs8vUt2mpWIH1PEZksIptEZIOIfC4iF1eXvb7MMjWqal1KEyKN2ojIm/74LheRKyuYvrOI/E1E1onIZhGZKyI3VOXYJFhuWTq1EZFnRWSN30ZWtZwQ6VRHRCaIyBYRWSUiN1QwfZh8qUp1KU1YNPJl9BeRWSKy3fvTORVImxZfimNPdxH5V0C/68pLk+iV4GBVbQB0B3oAI8ooPNS9fQX5k6o2CGyRRBKJyNHAVOCfQD7QDPgtcEr1mVpMLI2K6wI0TrQuIecF4AdgH2AgcI+I9EskoYh0Aj4DlgG/UNVGwFDcMWtYPeaWoLROfwfqAR1xX+z+tYj8TwrsSAUjgQOADkA/4GYRGZBIwhD60kgqWZcwIyIHAy8CtwONgEOBLxNMm25fKm1Pc+A94Anc+ZIPvF9uQlWNu+E+otg/8P/9wDv+twJXAf8BfvD7BgGzgU3AdOCQQNrDgVnAVuBlYCJwtw/rCywPxG0HTALWAuuB/wMOAnYCEWAbsMnHrQM8APwIrAbGAXUDed0ErAR+Ai7xdufHqO8zRTZVdAOmAY/HCS9dx+HA9/54fAucGQjLxzUAm4F1wMt+vwAPA2uALcDXwIqyNPJ1ySqNgAY+rEVg33jg+QQ1egF4N054R59/Lf//xcB8fzwWA1cE4jb3x3kTsAH4BKjhw27xumwFFgC/pGxf2gUcGdBpHbAz03XycX8CTgr8PwqYmKG+9BMlfWmjP+aZrtGLwKhKtndp86UY5d1Dgu1AiXQJVHRJ0UnhhZpXdNB8BT8AmgJ1vehrgKNwXzn+jU9fB6gNLAWuB/KAIUBBWSeFTzvHn6D1gb2APj5sGDCtlI0PA295OxoCbwP3+rAB/kTp5vN6sZyT4hkvwgbciOjsBE+Iev5k7VcBxx0KtMZdkZ8LbAda+bCXcKOzGqXqf7K3qzHOiQ/CjcT20IjdnWABzlHPz3SNfFoFWgb2PQl8laBOq4CLK+C4A4FO/lgfD+wAuvuwe3ENUJ7fjvXxunhNWgfy7ETZvrQDdwVY5Et34xrYTNepiQ/bJ7BvCPB1BvrS/b4uwfbuV7jOMGM18vEX49qKr3Ed5wtA07D7UozypgKP4gYja/xxaV9uPRKo6BL8KMSLOgY/6vAVPCEQdyylRhW4nvt44DjcyEQCYdNjnBRH40ZEtcqwp8RJ4Q/U9uCB8el/8L8nAPcFwjqXc1J0x11K1wJOxY0+jkngOLXx+R6YqOOWET4bON3/fg53hdO2VJwTgIVAL3aPlMrUyNdFgf6BuryeBRpNA/6Mayy64wYsCxJ03AJgQKKOW0b4G8B1/vddwJul7cRdeazxxz2vHF96CXcFoMCFuKuZ/5LhvoTrQBTYK7DvRGBJBvpSPrs7wRMCddmSyRr58F2+zp1xsyyvAX8Nuy/FyG+h1+1IXNvwGPDv8uqR6D3BM1S1sap2UNX/VdWfA2HLAr87ADf6G9mbRGQTzhla+22Fems9S2OU1w5YqqqFCdjWAjdy/DJQ5nt+P77coI2xygRAVWep6npVLVTVycBfgbMSsGMjEAVaJRAXABG5SERmB+zuhpsWALgZd8J/LiLzROQSb99U3FTJ48AaERnv4+2hkarOKqpzoC6HkuEaARcA+/k0Y3Gj10RXCq6nYhqdIiIz/MKMTbjBRJFG9wOLgPdFZLGIDAdQ1UXA73D3kdaIyEQRae3TlNAJN71W5E934jrF5WS+L23zf/cO7NsbNxArj1D5Eu6cKaKo/kX1ymSNwJ17T6vqQlXdhptSPDUBOyD9vlRWXV5X1S9UdSfw/4DeItIonl3JeEQiKPIyYLQ/gYq2eqr6Eu5Su42ISCB++xh5LgPax1hso6X+X4erfNdAmY3U3djGl9sugTJjoTjHiB9JdQfwKXB2IpmKSAfcNN7VQDNVbQx8U1SWqq5S1ctUtTVwBTBG/DJnVX1MVY8ADsaN4OKKzO5jprjGKaM1UtWlqjpIVVuo6lE4R/o8XpoAH5K4RnVwI+MHcNN6jYHJ7NZoq6reqKr7A6cBN4jIL33Yi6raB9eZKfDHGHXZoKoX+H9Pwfnk52S4L6nqRh//0MDuQ3HTi3EJmy8F6gK7j9mhuCuUjNXIM7dUGaXLi0eofKmydUn2c4JPAleKyFHiqC8iA0WkIe6kLgSuFZE8ETkLdy+kLD7HiXmfz2MvETnGh60G2opIbQBVjfpyHxaRllC8hP5kH/8VYJiIHCwi9XCj7ZiIyBC/JLqGiJyEm6J6KxCuItI3RvKbfVk3iUgzH/9QEZlYRtz6OJHW+ngX40avReUMFZG2/t+NPm5URI70xzcPNy2yM15ddv8srsvjZL5GB4lIQxGpLSIXAicBDwXCl4jIsBjJ78SNDu8XkX19/HwReUFEGpeKWxt3f2ctUCgip/iyisoZ5NMKbtFFBKdRFxE5wTv+TlyjFY1Rl05F5wpuCu1y3H3BjPcl3DTkCBFpIiIHApfh7lMX1T1jfMnXBWDvQF0eJfM1ehq4WET29/GH4xaoFB27jPElX5czReQwr+kfcFPJm+MegfLmSym1oq1U2B5zzbgbs1/g5mZXAn8DGvqwHsBX7F4t9TKxV0u1x80Zr8eNfh7z+2sD7+LuA63z+/bCXcYvxs3TzweuDeQ1HHcTN5HVUp94EbbgblafFwhr5/c3i3O8euKWvW/2Nn4GXBSjjqOL6oFrxP8JXOrD/oRbEbUNd5/ocr//l7gRzzaf7q+4KY89NPJ1UX+8i+uSBRr9DudM23H3B3sEwmp72+PdT+ri67ze6zTH51mTPW/mX4VriDYBz1Nyhd/1OP/YjpvC/IPffwiuYdvqj8E7uGmqJaV1As5h98rDb4GTs8iX6uDuUW3xx/CGDPalOuz2peK6ZLpGPv7/w/nTWtw53iTsvhTHnt96rTfiFsa0ixW3aBOf0EgAf9XRVVVvTbctRtmISB/gKlU9P922GLExXwo/ueJL1gkahmEYOUvGvEBbRAaIyAIRWSR+5ZARPkyn8GMahR/TKHVkxJWguPfQLcQ9m7McNwd/vqp+m1bDjBKYTuHHNAo/plFqyZQrwZ7AIlVdrKq7cDdUT0+zTcaemE7hxzQKP6ZRCsmUl163oeQDoMtxryoqgYhcjltiDnBECuxCVct9hjCHKFendGiEW1XXovxoOYFpFH6svUshmdIJJoSqjse9HgkRCf88bw6SJo3Ke2uGEcA0ygysvUsOmTIduoKSb0Fo6/cZ4cJ0Cj+mUfipFo3q1KnDzJkziUQivPHGG1XNLmvIlCvBL4ADRGQ/3MlwHu4t7tVGkyZNaN/evXFo6dKlXH/99XzzzTcsXLiQOXPmVGfRmUzKdTIqTLVo1KdPHz799FO6dOnCoEGDGDhwIO+++y4A06dPZ9q0av0ubLaRdI3q1KnDww8/zGGHHYaq8uWXCX0yMDco72n6sGy4l60uxL3x4fYE4mtltoEDB+oTTzyhCxYs0EgkopFIROfPn687duwo/j8YP93HJWxbRXSqrEaV2Gam+7iEaUumRnvvvbe+/fbbun37dl23bp1u2bJFo9FoiW379u26du1a06iaNEpEp5tuukkLCwv1/fff1169elXal9J9XKpjy5QrQdR9BWFydeR9/PHHM3Xq1JjhX3/9NV9//XV1FJ11VKdO+fn5NG/enDPPPJO+ffsSjUYZN24c//73v1m0aFF1FJmVJEujrl278vHHH9OsWTOWL1/ORRddxKJFi9i0aRPbtrmPSNSoUYM77riDESNG8Nprr3HppZeycePGqhad9STbjw444AAKCgoYPnw4s2bNKj9BLpHuXrgaR1IxRzPNmzfXUaNG6YABAxTQXr166YYNG3TZsmW6YcMGnThxoo4YMUJPPPFEbd68ec6NjMKgUXDr1q2bjhs3TtesWbPHVUY0GtVdu3bp2LFjtXbt2naVkUKNevXqpdFoVCORiF511VVxNbznnns0Go3qwIEDTaMU69S6dWuNRCL6ySefVHlWJd31rJZjl24DUn1S1K9fX2fNmqWRSERPO+204v0dO3ZUQNu3b681atTI6ZMi3RoVbYcccog+8cQTumnTpuIOb9myZfriiy/q6NGjtaCgQGfMmKHRaFSXLl2qV155pTWwKdTo+OOP12g0qhMmTEjIV6LRqD711FOmUYp1GjNmTEKdYK9evXTo0KHauXPnnGrv0m5Aqk+KN998UyORiI4aNUrr1atnI6MQagToE088UeLK74MPPtCHHnpI99prr+I4H330kR544IE6ffp0/eGHHzQSiWiLFi2sgU2RRv/61780Go3qFVdckXAnOG/ePOsEU6zT0qVLNRKJ6LBhw8oMHzt2rP7444+6detWLSws1A0bNugf/vCHnGnv0m5AKk+KBg0aaCQS0dWrV2ujRo2q3AFm60mRTo0AveOOOzQSiWg0GtXVq1fryJEjtX79+nvEmzt3rnbt2lVPOumk4s7SOsHUaLT//vvrokWLdOPGjdq7d2/rBEOqU7169XTFihX6448/lthfq1Yt7dmzp65YsUIjkYiqqq5Zs0Zff/11VVVdtmyZdujQISfau7QbkMqT4sILL9QffvhB27Ztm5QOMFtPinRqBOjWrVuLpz579uy5R3jNmjW1Y8eO+vvf/16XLl2qW7ZsUVXV5557TvPy8qyBTYFGd9xxh0ajUf3b3/6WsK9YJ5h6na699lotLCzUMWPGFO9r3bq1jhw5UgsLC7WwsFCXLVum99xzT3G7+NZbb2lhYWGZq0jTXc/q2DJmdWgy6N27N1999RXLly9PtylGHCKRCACFhYUcddRRDBkyhAMPPBCAn3/+mYMOOoiDDjqIdevWsc8++wCwevVq7r77bgoKCtJmdy5x3nnnsXnzZh599NF0m2LE4fDDDwfgP//5T/G+ESNGcMUVV6CqTJ06leuvv5558+YVhwfj5gI51QkOGTKEBg0acOedd/Lmm28ye/bsdJtklMFHH31E//79ad++PY899ljRSJdIJELNmjWL4xV1gNFolMMPP5yVK1emxd5c5bvvvrOH4ENO69atS/zfuXNnzj33XACefPJJrrvuOnbt2rVHulmzZuXMoxQ51Qm2aNGCaDRa/NzSuHHjmDFjBu3bt2fRokXFo6GuXbvy6aef2hVjmjjzzDNp3Lgxw4cP55hjjmH9+vX8+OOP1KlTh0MPPZSePXuWiD9+/HjrAFNMXl5euk0wEqBhw4aI7H7n9TXXXEPjxo158cUX+e1vfxszTUFBQZmdY1aS7vnYVM6R33///cVvfSlvW7VqlU6cONHuCaZYo/K25557rngRzObNm/V//ud/tGbNmuWls/tNSdYoGo3qp59+WiHtotGozpkzxzRKoU7//ve/tbCwUK+//noF9NVXX9XCwkL98MMPY+oUiURi3utNdz2rY8uUF2gnheHDh/P999+zdOlSotFo3LgtWrRgyJAhjBgxIkXWGeVx8803c9555xX/f+WVV/LUU08V30M0wssRR7gv/dx2221ptiS3ueKKK1i7di3HHHMMt956K82aNdsjzo4dO3jwwQfTYF16yKlOMBKJ0LlzZ/bff38GDBjAwIED+eKLL2LGF5Fi5zXSy6WXXsqIESOoVcvN4M+bN49Jkyal2SojEY444ghuuOEG/v3vfzNlypR0m5NTtGrVqsT/69evp3v37nzzzTeMGjWKSZMm0bBhQwAGDRrEjBkz+NOf/sSMGTPSYW56SPelaKqnB0pvw4cP10gkov/973913LhxesQRR+jzzz9fPC36+uuv23RomjXq2bOnbt68uXgadMuWLXrMMcdUZCrOptqSrNHmzZsTmg6tWbOmvvTSSxqNRvWoo44yjVKs05QpUzQSiejbb7+9x8tBBg0apJ06ddJ27drp+PHjNRKJ6NatW3OuvRN/ALOORD8yWbduXSZMmMA555xTYn8kEuHdd9/lwgsvZPv27THTaxZ+aTlVJKJRw4YNWbduXfFCjPHjx3PllVdWtKgvVbVHJUzMeWJp9O2333LggQcya9asMhcl9erVq3iqbd26dbz11ltceuml8YoyjapAPF9q1aoVH330Efn5+cH4BNv+Z555hltuuYX169fHLScb27uc7wTBLbX/y1/+Qo8ePWjZsiVLlizh+eefZ+TIkeWmzcaTIlWUp1GDBg2YP38+bdq0AWDu3Ln06tWLnTt3VrQoa2ArSSyNzjzzTEaMGFH8HFpZRKNRNmzYwEMPPcR9991XXlGmURUoz5caN27MueeeS35+Ppdddhl/+ctfijvBp556iu+++y6hcrKyvUv3pWipS/p2wEfAt8A84Dq/fyTu45Kz/XZqZacH4m2//vWv9fHHH9eWLVsmnCbdxyybNTrttNNUVYunQfv161dhTcnBqbZUadS6dWudO3dumV/2eOKJJ+K90DznNUqlTsnc0n3MqmML1ZWgiLQCWqnqLBFpCHwJnAGcA2xT1QcqkFdKKqbZODKKQyo1mjNnDr/4xS8AuP/++7nlllsqa3ZOXWVkoh+RYxpBZuqUje1dqB6WV9WVwEr/e6uIzAfapNcqI0gqNWratCkiwpo1a3jkkUeqo4isxPwoMzCdwkFoH5EQkY7A4cBnftfVIjJXRCaISJMYaS4XkZkiMjNFZuY01a3RQw89BMCoUaPsjTCVxPwoMzCd0keopkOLEJEGwD+B0ao6SUT2Adbh5qVH4aYQLiknD5seqEYySSNycKoNTKNMIZN0ysb2LnSdoIjkAe8AU1T1oTLCOwLvqGq3cvLZCiyoDhuB5riTtIOqtqimMkJLEjVaC2zHHctkU6QR5KBOGaIRmC9Ze5dmQnVPUNybXp8C5gdPCBFp5efPAc4EvkkguwXVNbIUkZk5PGpNmkaq2qK6jqVpFH6NvE2mk7V3aSVUnSBwDPBr4GsRKfrO0W3A+SJyGG56YAlwRXrMMzCNMgHTKDMwnUJAqDpBVZ0GlDXnPDnVthhlYxqFH9MoMzCdwkFoV4cmgfEZmneuUV3H0jRKHuZL4cc0qiShWxhjGIZhGKkim68EDcMwDCMu1gkahmEYOUtWdoIiMkBEFojIIhEZXoV82onIRyLyrYjME5Hr/P6RIrJCRGb77dTkWZ8bJEsjn5fpVA2YRpmBtXdVI+vuCYpITWAhcCKwHPgCOF9Vv61EXkl7wa2xm2Rq5PMznZKMaZQZWHtXdbLxSrAnsEhVF6vqLmAicHplMlLVlao6y//eCtgLbpND0jQC06maMI0yA2vvqkg2doJtgGWB/5eTBCEr84JbIybVohGYTknENMoMrL2rItnYCSYd/4Lb14DfqeoWYCzQCTgM9ymUB9NonuExncKPaRR+ck2jbOwEV+C+2FxEW7+vUvgX3L4G/FVVJwGo6mpVjahqFHgSNyVhJE5SNQLTqRowjTIDa++qSDZ2gl8AB4jIfiJSGzgPeKsyGcV7wW0gWqIvuDV2kzSNwHSqJkyjzMDauyoSqneHJgNVLRSRq4EpQE1ggqrOq2R29oLbaiDJGoHplHRMo8zA2ruqk3WPSBiGYRhGomTjdKhhGIZhJIR1goZhGEbOYp2gYRiGkbNYJ2gYhmHkLNYJGoZhGDmLdYKGYRhGzmKdoGEYhpGzWCdoGIZh5CzWCRqGYRg5i3WChmEYRs5inaBhGIaRs1gnaBiGYeQsae0EReQZEbnb/z5WRBakqFwVkfxUlFWq3I6+7Iz6ekcO6tRXRJanutyqkIMaZZwv5aBGGeFH5XaCIrJERH4WkW0istoL2SDZhqjqJ6raJQF7honItGSXH8i/jYi8KSIbRGS5iFxZwfSdReRvIrJORDaLyFwRuUFEalaXzb7csnRqIyLPisgav42sajkh0qmOiEwQkS0iskpEbqhg+p4iMllENnmtPxeRi6vLXl9mmb5U1bqUJkQanSMi00Vkh4h8XIn0KfelOBr1E5GPvB1LqlpOiDR6RkR2+foWbQkf33T4URxbKlWXPqPTDAAAE6RJREFURK8EB6tqA6A70AMYUYYBGTMiK4cXgB+AfYCBwD0i0i+RhCLSCfgMWAb8QlUbAUNxx6xh9ZhbgtI6/R2oB3TEfQ361yLyPymwIxWMBA4AOgD9gJtFZEAiCUXkaGAq8E8gH2gG/BY4pVosLUlZvjSSStYl5GwAHgHuq2jCNPtSWRptByYAN3n7sqW9A/iTqjYIbJFEEqXZj2JR8bqoatwN9xHF/oH/7wfe8b8VuAr4D/CD3zcImA1sAqYDhwTSHg7MArYCLwMTgbt9WF9geSBuO2ASsBZYD/wfcBCwE4gA24BNPm4d4AHgR2A1MA6oG8jrJmAl8BNwibc7v4y6NvBhLQL7xgPPl3ecfNwXgHfjhHf0+dfy/18MzPfHYzFwRSBuc+Adfxw3AJ8ANXzYLcAKn24B8MsYOu0CjgzotA7Ymek6+bg/AScF/h8FTExQp2nA43HCS9dxOPC9Px7fAmcGwvJxjcBmf3xf9vsFeBhYA2wBvvaa7eFLvi5BX9roj3lGaxRIcynwcSLahMCXVpWlUaC9ewwoIAvaOx/3mSKbKrqRPj/qlsy6VKgT9ELNA0YFTooPgKZAXS/6GuAo3FeOf+PT1wFqA0uB64E8YIg/mfY4KXzaOb7y9YG9gD4+bBgwrZSNDwNveTsaAm8D9/qwAf5E6ebzejHWSeHTKtAysO9J4KsET4pVwMUVcNyBQCcv9PHADqC7D7vXn9x5fjvWx+uCGx23DuTZKYZOO3BXgEU63Y1rYDNdpyY+bJ/AviHA1wloVA/XqPSrgPMOBVrjZk7OxV0VtPJhLwG3+7Bg/U8GvgQae90O8rqV1uh+X5egL/0K1xlmrEal8qxMJ5guX1pehkbB9u5LXOeT8e2dj/8MbmCwwdft7AT1SacftUpqXRKo7BL8KMSLOgY/6vAH94RA3LFFJ0xg3wLcSXkcbmQigbDpMU6Ko3Ejolpl2FPipPAHZjvQKbDvaHaP1CYA9wXCOpdzUkwD/uyF6O4P6IIET4wCYECijltG+BvAdf73XcCbpe3EjZjWAP2BvHJ0egk3ulTgQtwo7L+ZrhOucVJgr8C+E4ElCWjUxqc9MFHnLSN8NnC6//0cbragbak4JwALgV7svuooS6N8dneCJwTqsiWTNSpVTmU6wbT4UgyNgu3d74vOMzLcj3x4d9w0Zi3gVNxV2jFh9qM4+VWqLoneEzxDVRuragdV/V9V/TkQtizwuwNwo79JuklENuEarNZ+W6HeWs/SGOW1A5aqamECtrXAjUq+DJT5nt+PLzdoY6wyi7gA2M+nGYublkl0hdN6oFWCcRGRU0Rkhr+hvAknXHMffD+wCHhfRBaLyHAAVV0E/A53H2mNiEwUkdY+TQmdcNNrRVrdiesUl5P5Om3zf/cO7Nsbd9KXx0YgSsV0ukhEZgfs7sZunW7GNUyfi8g8EbkEQFWn4qa0HsfpNN7HK63R+kBRRfUvqlcma1RV0uJLuKuyeO3d2sDvTPcjVHWWqq5X1UJVnQz8FTgrATvS5kcisndZ+Ve2Lsl4RCIo8jJgtD+BirZ6qvoSbo66jYhIIH77GHkuA9rHuPmspf5fh2vouwbKbKTuxja+3HYJlOkyV12qqoNUtYWqHoUT6fN4aQJ8CJydSEQRqQO8hpvb30dVGwOTcScCqrpVVW9U1f2B04AbROSXPuxFVe2Dc0IF/hijLhtU9QL/7yk4vT8nw3VS1Y0+/qGB3Yfipq7ioqo7gE9JXKcOuCnxq4FmXqdv2K3TKlW9TFVbA1cAY8QvR1fVx1T1COBg3Ii8UZy6wO5jdijuCiVjNUoC6fKlJuUUl1XtXYzypNxI6fWjm5JZl2Q/J/gkcKWIHCWO+iIyUEQa4g5YIXCtiOSJyFm4+1Vl8TlOzPt8HnuJyDE+bDXQVkRqA6hq1Jf7sIi0hOLHHE728V8BhonIwSJSD3dFFBMROUhEGopIbRG5EDgJeCgQvkREhsVIfifQW0TuF5F9ffx8EXlBRBqXilsbd+9gLVAoIqf4sorKGeTTCu5mcQSIikgXETnBO/5OnENEY9Slk4g08/8eB1yOuy+Y8Trhpk9GiEgTETkQuIz/3975x1ZVpnn88wB1FceNpO0fRWE7kbG4lYVpkT+YIV6jq4CpQxUmooi7iVaaITuw4qZMolQbJW7EsJtooWYYAhl/RAqCurQmtW3gn6GdUkBKHBGHoKlAiVWLEunts3+c08ttoT8uvfeec+55Psmb3p4f73ne873v+973ed/zHGdOoL/sKiKRIc79L/daz/TfHxGZ6Y4EBnM9TmU66x737zi/YPuvs0REbnb//cY9tk9E7nDvbxaO++rCCGUB+Me4svwPAddIRMaLyLU47qlx7rWz4vb7sS4NVZb+tnKC869cC/yJ4Gu0WJxHQMaJyL040yZ74vb7sR4N1d4NW5YhGclfyqBVh4P2XeZrxpmYbcHxqXcC7wI3uPtmAwe5tFrqHYZeLTUVx69/DufXz/+6268BPsSZq+tyt10LvISzKuw7nFVi/xGXVwXORPtoVkutcoU6jzM/ODtu3zWu7cP5wQvcMp/DqXCH3DzHc/lk/u9wvuTdwHYGrh5b7d778zguzGfd7f+CU2m+d+/BBzgukMt0An7LpZWHHcB9GaTTP+DMf3zn3sP/jNs3xd2ePYxOc3AeIfnWtfEvwPIhyvhifzlwfhA1A0+4+/4bZ3VhD86ca5m7/W7gsLu9C8c1c3KwRnFlUfd+x8qSARr9G5fmO/vTVp/XpdjipUG2RK5QlqYM0Gife2+/c+/vwwGoRz9LtCzDJXFPNkaBiPwa+J2qLvXaFmNoxBnBF6rqWq9tMa6M1SX/E5Z6ZJ2gYRiGEVosgLZhGIYRWgLTCYrIfBH5VESOi7vE2fAfppP/MY38j2mUPgLhDhUnCOrfcB4i/hJnInqpqnZ4apgxANPJ/5hG/sc0Si9BCQI7BziuqicA3CW4v8FZ8XhFRCQtvbuqjvgcSohISKd0aYSzqi535MNCgWnkf6y9SyNBcYfexMAoCF+62wYgImUi0ioirWmzzIhnRJ080iiVkU2Chmnkf6y9SyNBGQmOClWtwYk/l85fsEYCmEb+xzQKBqZTcgjKSPArBoYCutndZvgL08n/mEb+xzRKI0HpBFuAX4jIz93wQQ8zmnA4RroxnfxPSjWqrKxEVWlsbExWlmEkpRoVFxdTVVVFR0cH0WiUvr4+otEoLS0tbNu2beQMMoxAuENVtVdEVgL1OCGTtqjqiMGSjfSSSp0mTZrErFmzWLBgAc888wx9fX3s2LGDkydPsmHDBk6fPp2My2Q8qa5Ld955JwCRSIRIJEJTU1Oysg4NydaorKyM6dOnM2/ePACKioqccGEiqCo1NTXs2rWLjz76KDkFCBqjia0WxMTlcf6GTLNmzdL3339fo9GoqqpGo1F95513dNq0aXr99dfrddddN+S5XpczyGk02qxcuVJ7e3sHpI8//viybSPk0+p1WYOaEqlHbn2IkeC5plGKdNqxY4f29vZqS0tLopqEor3z3AAvvhT9KSsrS++55x49depUrDGNRqOxz1u3btWGhgZdtmxZqL4UftGosLBQT58+PaCzW7NmjWZlZen69eutE/SBRtYJ+iMNd29zc3P1iy++0DNnzujUqVOtExyUgjInmBKKioqoq6sjLy+Pzs5OHnroIebPn8+CBQtYsWIF9fX1zJw5k87OzpEzM5JKYWEh69evJyfHeefmyZMnmTlzJq+++ioXL17kueeeY+7cuXR1dXlsqRHP888/H/tcWVnpnSFGjLNnz1JTU0N2dnasPhmXCMScYCooLCxkzx5nrrmhoYG1a9fS1tYW2z958mR2797NjTfeSENDg1dmhpaioiLuv/9+xo0bx08//cTrr7/O0aOXpkUuXrzIgQMH2Lp1K08//TQ1NTWUlZV5aLEBsG7dOq9NMK7AuHHjEBFuu+02JO49v8eOHeOHH37w0DIf4PVQ1Av3AKBvv/22RqNR3bNnj06bNu2y/ffee++oXG1elzPIabj7+uabb8bc0/X19cNqcOjQIW1razNXW5o1GqI+xKisrDR3qA906neH9k/1xP/dsWOHlpaWhtodGsqR4BtvvMGSJUs4f/48FRUVHD9+fMD+rKws1q5di4jQ3NzskZXhJTs7mzlzLr2Ee/v27cMev337dh555JFUm2UYgSM3N5fm5mamTp1KW1sbx44dY//+/QA8+eSTFBcX8+CDD6KqzJkzJ5Qjw1B2grNnz0ZV6enpoaNjYDi+rKwsqqqqmDdvHqrKCy+84JGV4aW4uJj8/HwA9u3bx4cffjjiOZMmTYrN7RqG4VBQUEBBQQE7d+5kyZIlA/bV1NSQk5PDsmXLWLRoEQcOHKCjo4MZM2Z4ZK03hHphzGDy8/N58cUXWbNmDQCdnZ20t7d7bFX4KC4ujn1et24d33zzzYjnTJkyhdtvvz2VZhkJYgtjvGf//v2MHz/+sg6wn66uLjZu3EgkEqG8vJwLFy4MqH9hIJQjwf5fO9nZ2Rw8eDC2PScnh8mTJ/f72GloaKC7u9srM0PLxIkTY5P3o3VHx0/2G4aRODU1NezcuZNPPvmE8vJydu3a5bVJaSGUI8EnnniCvXv3MmHCBGbMmBFLeXl5PPDAA9TW1gKwadMmjy0NJ3fccUf8hP+oSORYwzCuTFdXF6dOnWLz5s2sWrXKa3PSQig7wR9//JGSkhLuvvtuKioqqKiooKSkhAkTJrBw4UIWL17MZ599xueff+61qcYo6enp4dy5c16bYRiBZ8GCBZw9e5ZXXnnFa1PSg9fLU71YMjxc6l8+vG3bttAuGfZao7q6utFGglFADx8+rKtWrbLl92nUaKjU2Nio/dgjEv7VaaS0efNmjUajoWjvQjkSHIr+FYk9PT1s3LjRW2NCTEVFRSwSzJYtW0Y8Picnx1zXhpEkpk+fzqJFiy5bOZ+pWCfoUlhYGFsJunLlygHRY4z00t7ezty5c3nrrbd4/PHHWb169RWPu+uuu+jq6kJEuHDhQpqtNAbT2NhIJBLx2gwjjtLSUqLRKNXV1UMek5ubS1lZGWVlZezdu5d3332XFStWhOdRCa+HooOG9FOARqADOAr83t1eifNSyXY3LUy2e+Cxxx6LuUIXL14c6ggKftEoPz9fT5w4od3d3frSSy/Ftt9666366KOP6pkzZ7S3t1dffvllc7V5pFF/ikQiGk8kEknUBRcqjdKlU2lpqao6b8Y5c+aMbtq0STdv3qzNzc1aW1ur0WhU+/r6Yn+PHj2qOTk5oWrvPDdgkJB5QJH7+Qbgb8A/u1+KNQnmlVAlXL16tfb29uqhQ4cSOs/re5bpGuXl5enu3bu1u7tbDx48qE899dSAN0u89957esstt1gD66FG8Z1ggvOAodUonTrdd999Wl1drdXV1fr1119rNBrVI0eOaFNTk1ZXV2tVVZUWFRVpUVGRTpw4MXTtna+eE1TVTqDT/fy9iBwDbkrHtZcvXw6MHKIr7KRbo87OTpYvX05BQQHPPvssr732Ghs2bACgtraWtrY2ent7U3X5QOJFPWpqarJnNRMkXTrV19dTX18PQHl5ebKzDzy+6gTjEZF84JfAX4BfAStFZDnQCjytqiOHEUmAMIYLGivp0ujbb7/lwIEDlJSUJCO7UJHuemRcHaaTd/hyYYyI/AyoBVap6ndANXALMAvnl9OGIc4rE5FWEWlN9Jp1dXW0trbS0tIyBsvDgxcaGYlhGgUD08lbxPUn+wYRyQI+AOpV9dUr7M8HPlDVYQNFikhaCqaqofMBBU0j4K+qOjtN1/IFplEwCJpOmdje+codKs6kwh+BY/FfCBHJc/3nAKXAJ6PIrgf4NPlWApADdAH/lKL8fUuSNeoCzrt/k02/RhAynQKkEVhdsvbOY3w1EhSRXwP7gCNAn7v5D8BSHNeAAn8Hnor7kgyVV2uqflmmMm+/k0yN3PxSci9NI/9rlOq8/Y61d/7AVyNBVd0PXGm4/X/ptsW4MqaR/zGNgoHp5A98uTDGMAzDMNJBJneCNQHNO2yk6l6aRsnD6pL/MY2uEl/NCRqGYRhGOsnkkaBhGIZhDIt1goZhGEZoychOUETmi8inInJcRCrGkM8UEWkUkQ4ROSoiv3e3V4rIVyLS7qaFybM+HCRLIzcv0ykFmEbBwNq7sZFxc4IiMh4nGvu/Al8CLcBSVU34DZEikgfkqWqbiNwA/BVYBPwW6FHVV5JneXhIpkZufqZTkjGNgoG1d2MnE0eCc4DjqnpCVX8C3gZ+czUZqWqnqra5n78H0vZWiwwnaRqB6ZQiTKNgYO3dGMnETvAm4FTc/1+SBCEHRXkHJ8r7YRHZIiKTxpp/yEiJRmA6JRHTKBhYezdGMrETTDpXG+XdSC+mk/8xjfxP2DTKxE7wK2BK3P83u9uuCjfKey3wZ1XdCaCqp1U1qqp9wBs4Lglj9CRVIzCdUoBpFAysvRsjmdgJtgC/EJGfi8g1wMPAnqvJaLgo73GHjTbKu3GJpGkEplOKMI2CgbV3Y8RXAbSTgar2ishKoB4YD2xR1aNXmd2vgMeAIyLS7m77A7BURAZEeR+b1eEiyRqB6ZR0TKNgYO3d2Mm4RyQMwzAMY7RkojvUMAzDMEaFdYKGYRhGaLFO0DAMwwgt1gkahmEYocU6QcMwDCO0WCdoGIZhhBbrBA3DMIzQ8v/ggtbd0utdMwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#인공지능이 구분하지 않은 그림\n",
        "plt.figure()\n",
        "for i,incorrect in enumerate(incorrect_indices[:9]):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.imshow(X_test[incorrect].reshape(28,28),cmap='gray',interpolation='none')\n",
        "  plt.title(\"Predicted {},Class{}\".format(predicted_classes[incorrect],y_test[incorrect]))\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "At-5crWuU2kd",
        "outputId": "bd6046f4-c82e-49ce-e27a-d74daecdcb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(mnist_x_train, mnist_y_train),(mnist_x_test,mnist_y_test)=tf.keras.datasets.mnist.load_data()\n",
        "print(mnist_x_train.shape, mnist_y_train.shape)\n",
        "\n",
        "(cifar_x_train,cifar_y_train),_=tf.keras.datasets.cifar10.load_data()\n",
        "print(cifar_x_train.shape,cifar_y_train.shape)\n",
        "\n",
        "#이미지 출력\n",
        "print(mnist_y_train[0:10])\n",
        "plt.imshow(mnist_x_train[0],cmap='gray')\n",
        "\n",
        "print(cifar_y_train[0:10])\n",
        "plt.imshow(cifar_x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "3fFkrJrm5POv",
        "outputId": "c364d3b4-22a4-46a7-e903-e974fffb490f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(50000, 32, 32, 3) (50000, 1)\n",
            "[5 0 4 1 9 2 1 3 1 4]\n",
            "[[6]\n",
            " [9]\n",
            " [9]\n",
            " [4]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [7]\n",
            " [8]\n",
            " [3]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f26d7e4c890>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "#데이터 로드\n",
        "(Xdata,Ydata),_=tf.keras.datasets.mnist.load_data()\n",
        "print(Xdata.shape,Ydata.shape)\n",
        "\n",
        "#데이터 준비\n",
        "#reshape, one-hot encoding\n",
        "Xdata=Xdata.reshape(60000,784)\n",
        "Ydata=pd.get_dummies(Ydata)\n",
        "print(Xdata.shape,Ydata.shape)\n",
        "\n",
        "#모델 생성\n",
        "X=tf.keras.layers.Input(shape=[784])\n",
        "#H는 히든레이어, 모든 레이어를 다 사용하는 Dense, 노드의 개수는 84개임(마음대로 지정한것)\n",
        "H=tf.keras.layers.Dense(84,activation='swish')(X)\n",
        "Y=tf.keras.layers.Dense(10,activation='softmax')(H) #출력 레이어는 10개이다. 원핫인코딩으로 0개부터 9개까지 분류하라고했으니까 10개임\n",
        "model=tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "#모델 학습\n",
        "model.fit(Xdata,Ydata,epochs=10)\n",
        "\n",
        "#모델 예상,round(2)는 소수 두째자리 반올림\n",
        "pred=model.predict(Xdata[0:5])\n",
        "print(pred.round(2))\n",
        "Ydata[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "O102P_Lq7o-Y",
        "outputId": "6af13e98-ec72-47d1-b774-89cefea9dcc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(60000, 784) (60000, 10)\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.3040 - accuracy: 0.8527\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5729 - accuracy: 0.9182\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4768 - accuracy: 0.9328\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4427 - accuracy: 0.9402\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4259 - accuracy: 0.9424\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3806 - accuracy: 0.9475\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3672 - accuracy: 0.9505\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3490 - accuracy: 0.9498\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3478 - accuracy: 0.9535\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3437 - accuracy: 0.9547\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9\n",
              "0  0  0  0  0  0  1  0  0  0  0\n",
              "1  1  0  0  0  0  0  0  0  0  0\n",
              "2  0  0  0  0  1  0  0  0  0  0\n",
              "3  0  1  0  0  0  0  0  0  0  0\n",
              "4  0  0  0  0  0  0  0  0  0  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c691c71-b116-4e91-b1c2-d66eff8f3a0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c691c71-b116-4e91-b1c2-d66eff8f3a0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c691c71-b116-4e91-b1c2-d66eff8f3a0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c691c71-b116-4e91-b1c2-d66eff8f3a0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "#데이터 로드\n",
        "(Xdata,Ydata),_=tf.keras.datasets.mnist.load_data()\n",
        "print(Xdata.shape,Ydata.shape)\n",
        "\n",
        "#데이터 준비\n",
        "#reshape, one-hot encoding\n",
        "Ydata=pd.get_dummies(Ydata)\n",
        "print(Xdata.shape,Ydata.shape)\n",
        "\n",
        "#모델 생성\n",
        "X=tf.keras.layers.Input(shape=[28,28]) #reshape 할 때는 총 개수가 맞아야함. 즉size가 같아야 shape을 변환할 수 있음.아님 에러남\n",
        "H=tf.keras.layers.Flatten()(X)\n",
        "H=tf.keras.layers.Dense(84,activation='swish')(H)\n",
        "Y=tf.keras.layers.Dense(10,activation='softmax')(H) #출력 레이어는 10개이다. 원핫인코딩으로 0개부터 9개까지 분류하라고했으니까 10개임\n",
        "model=tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "#모델 학습\n",
        "model.fit(Xdata,Ydata,epochs=10)\n",
        "\n",
        "#모델 예상,round(2)는 소수 두째자리 반올림\n",
        "pred=model.predict(Xdata[0:5])\n",
        "print(pred.round(2))\n",
        "Ydata[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "p_mDoQ0kA5uw",
        "outputId": "45509fc9-0b62-4701-d00c-13ae8e3f2964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(60000, 28, 28) (60000, 10)\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.0437 - accuracy: 0.8502\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5123 - accuracy: 0.9162\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4485 - accuracy: 0.9284\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4157 - accuracy: 0.9365\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4009 - accuracy: 0.9392\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3754 - accuracy: 0.9426\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3869 - accuracy: 0.9437\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3582 - accuracy: 0.9467\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3471 - accuracy: 0.9476\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3599 - accuracy: 0.9479\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9\n",
              "0  0  0  0  0  0  1  0  0  0  0\n",
              "1  1  0  0  0  0  0  0  0  0  0\n",
              "2  0  0  0  0  1  0  0  0  0  0\n",
              "3  0  1  0  0  0  0  0  0  0  0\n",
              "4  0  0  0  0  0  0  0  0  0  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aaaa7e81-b289-4cc5-910b-7e9f72a0a93d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aaaa7e81-b289-4cc5-910b-7e9f72a0a93d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aaaa7e81-b289-4cc5-910b-7e9f72a0a93d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aaaa7e81-b289-4cc5-910b-7e9f72a0a93d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/11주 10장 convolution의 원리 4번째 그림에서/\n",
        "-1,-2 이렇게 -가 나온것은 계산에만 그렇게 나오고 실제로는 0을 의미함.\n",
        "CNN은 손글씨를 잘게 쪼개 특징을 뽑아내어 이건 동그라미이고, 세모라는 것을 알기위해 계속 쪼개는것을 합성곱(comvolution)이라고함\n",
        "/11주 16장/4라는 숫자가 있으면 4숫자의 픽셀에 값이 있는지 없는지 알 수 있음. 하지만 평탄화,  flatten작업을 통해 1차원으로 배열펼치면 훼손됨."
      ],
      "metadata": {
        "id": "FcNibOQCHGYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "#데이터 로드\n",
        "(Xdata,Ydata),_=tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "#데이터 준비\n",
        "Xdata=Xdata.reshape(60000,28,28,1)\n",
        "Ydata=pd.get_dummies(Ydata) #원핫 인코딩으로 바꿈\n",
        "\n",
        "#모델 생성\n",
        "X=tf.keras.layers.Input(shape=[28,28,1])\n",
        "H=tf.keras.layers.Conv2D(3,kernel_size=5,activation='swish')(X) #Conv2D만 써도 cnn은 적용이됨. 3은 필터(커널)몇장 쓸지(사용자가 지정), 사이즈도 사용자 지정\n",
        "H=tf.keras.layers.Conv2D(6,kernel_size=5,activation='swish')(H)\n",
        "H=tf.keras.layers.Flatten()(H)\n",
        "H=tf.keras.layers.Dense(84,activation='swish')(H)\n",
        "Y=tf.keras.layers.Dense(10,activation='softmax')(H)\n",
        "model=tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "#모델 학습\n",
        "model.fit(Xdata,Ydata,epochs=10)\n",
        "\n",
        "#모델 이용(예상) 및 정답확인\n",
        "pred=model.predict(Xdata[0:5])\n",
        "print(pred.round(2))\n",
        "Ydata[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "lmh03MUNJ6mL",
        "outputId": "622c6f83-b383-4859-9bf3-0639f4379b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 19s 4ms/step - loss: 0.4141 - accuracy: 0.9332\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0803 - accuracy: 0.9785\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0555 - accuracy: 0.9846\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0401 - accuracy: 0.9887\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0304 - accuracy: 0.9916\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0250 - accuracy: 0.9929\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0228 - accuracy: 0.9940\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0223 - accuracy: 0.9942\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0199 - accuracy: 0.9950\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0174 - accuracy: 0.9953\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9\n",
              "0  0  0  0  0  0  1  0  0  0  0\n",
              "1  1  0  0  0  0  0  0  0  0  0\n",
              "2  0  0  0  0  1  0  0  0  0  0\n",
              "3  0  1  0  0  0  0  0  0  0  0\n",
              "4  0  0  0  0  0  0  0  0  0  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-479ed33d-e13a-4e36-95bd-36f844e0c503\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-479ed33d-e13a-4e36-95bd-36f844e0c503')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-479ed33d-e13a-4e36-95bd-36f844e0c503 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-479ed33d-e13a-4e36-95bd-36f844e0c503');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cnn은 실행하는데 너무 오래기 때문에 Pooling으로 이미지 사이즈를 줄여야함\n",
        "MaxPool2D는 풀링을 하는데 맥스값만 주겠다는 뜻"
      ],
      "metadata": {
        "id": "3fU9XFZZNpZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "#데이터 로드\n",
        "(Xdata,Ydata),_=tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "#데이터 준비\n",
        "Xdata=Xdata.reshape(60000,28,28,1)\n",
        "Ydata=pd.get_dummies(Ydata) #원핫 인코딩으로 바꿈\n",
        "\n",
        "#모델 생성\n",
        "X=tf.keras.layers.Input(shape=[28,28,1])\n",
        "H=tf.keras.layers.Conv2D(3,kernel_size=5,activation='swish')(X) \n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "H=tf.keras.layers.Conv2D(6,kernel_size=5,activation='swish')(H)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "H=tf.keras.layers.Flatten()(H)\n",
        "H=tf.keras.layers.Dense(84,activation='swish')(H)\n",
        "Y=tf.keras.layers.Dense(10,activation='softmax')(H)\n",
        "model=tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "#모델 학습\n",
        "model.fit(Xdata,Ydata,epochs=10)\n",
        "\n",
        "#모델 이용(예상) 및 정답확인\n",
        "pred=model.predict(Xdata[0:5])\n",
        "print(pred.round(2))\n",
        "Ydata[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "fG_nAB83OxRk",
        "outputId": "0df3834e-7b5f-46a6-bd96-9bbb8c837bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.7663 - accuracy: 0.8644\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1576 - accuracy: 0.9534\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1165 - accuracy: 0.9658\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0969 - accuracy: 0.9717\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0899 - accuracy: 0.9739\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0840 - accuracy: 0.9763\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0825 - accuracy: 0.9764\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0750 - accuracy: 0.9784\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0738 - accuracy: 0.9787\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0746 - accuracy: 0.9791\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9\n",
              "0  0  0  0  0  0  1  0  0  0  0\n",
              "1  1  0  0  0  0  0  0  0  0  0\n",
              "2  0  0  0  0  1  0  0  0  0  0\n",
              "3  0  1  0  0  0  0  0  0  0  0\n",
              "4  0  0  0  0  0  0  0  0  0  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e402398c-97c1-4681-bc8a-9ad8c56ab074\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e402398c-97c1-4681-bc8a-9ad8c56ab074')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e402398c-97c1-4681-bc8a-9ad8c56ab074 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e402398c-97c1-4681-bc8a-9ad8c56ab074');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ee60v4T7UUem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#리넷을 mnist데이터로 이용했을 때 어떻게 쓸지\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "#데이터 준비\n",
        "(Xdata,Ydata),_=tf.keras.datasets.mnist.load_data()\n",
        "Xdata=Xdata.reshape(60000,28,28,1)\n",
        "Ydata=pd.get_dummies(Ydata)\n",
        "\n",
        "#모델 생성\n",
        "X=tf.keras.layers.Input(shape=[28,28,1]) \n",
        "                       #개수는6개, 커널사이즈는 5개 패딩은 크기가 줄어들때 옆을 키워라, 여기까지 상자1번 끝냄(영어 그리기 옆 상자부터 숫자셈.)\n",
        "H=tf.keras.layers.Conv2D(6,kernel_size=5, padding='same',activation='swish')(X)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=tf.keras.layers.Conv2D(16,kernel_size=5,activation='swish')(H)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=tf.keras.layers.Flatten()(H)\n",
        "H=tf.keras.layers.Dense(120,activation='swish')(H)\n",
        "H=tf.keras.layers.Dense(84,activation='swish')(H)\n",
        "Y=tf.keras.layers.Dense(10,activation='softmax')(H) #여기까지가 히든레이어로 모델생성함.\n",
        "\n",
        "model=tf.keras.models.Model(X,Y)\n",
        "                                              #평가방법은 정확도를 찍어라\n",
        "model.compile(loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "#모델 학습\n",
        "model.fit(Xdata,Ydata,epochs=10)\n",
        "\n",
        "#모델 이용(예상) 및 정답확인\n",
        "pred=model.predict(Xdata[0:5])\n",
        "print(pred.round(2))\n",
        "Ydata[0:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "Ue_bXMs2AGWK",
        "outputId": "5a274961-658d-46e4-e79c-92e5f412ebeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 21s 4ms/step - loss: 0.3795 - accuracy: 0.9319\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0906 - accuracy: 0.9765\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0761 - accuracy: 0.9814\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0703 - accuracy: 0.9830\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0695 - accuracy: 0.9834\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0673 - accuracy: 0.9850\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0714 - accuracy: 0.9846\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0710 - accuracy: 0.9853\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0738 - accuracy: 0.9850\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0675 - accuracy: 0.9862\n",
            "[[0.   0.   0.   0.03 0.   0.97 0.   0.   0.   0.  ]\n",
            " [1.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
            " [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9\n",
              "0  0  0  0  0  0  1  0  0  0  0\n",
              "1  1  0  0  0  0  0  0  0  0  0\n",
              "2  0  0  0  0  1  0  0  0  0  0\n",
              "3  0  1  0  0  0  0  0  0  0  0\n",
              "4  0  0  0  0  0  0  0  0  0  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0ee343b-3dac-4027-88e5-3a5029513199\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0ee343b-3dac-4027-88e5-3a5029513199')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0ee343b-3dac-4027-88e5-3a5029513199 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0ee343b-3dac-4027-88e5-3a5029513199');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "(Xdata,Ydata),_=tf.keras.datasets.cifar10.load_data()\n",
        "Ydata=pd.get_dummies(Ydata.reshape(50000))\n",
        "\n",
        "X=tf.keras.layers.Input(shape=[32,32,3])\n",
        "\n",
        "H=tf.keras.layers.Conv2D(6,kernel_size=5, padding='same',activation='swish')(X)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=tf.keras.layers.Conv2D(16,kernel_size=5,activation='swish')(H)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=tf.keras.layers.Flatten()(H)\n",
        "H=tf.keras.layers.Dense(100,activation='swish')(H)\n",
        "H=tf.keras.layers.Dense(80,activation='swish')(H)\n",
        "Y=tf.keras.layers.Dense(10,activation='softmax')(H) \n",
        "\n",
        "model=tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "model.fit(Xdata,Ydata,epochs=10)\n",
        "\n",
        "pred=model.predict(Xdata[0:5])\n",
        "print(pred.round(2))\n",
        "Ydata[0:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "ccmXGHyyM4aZ",
        "outputId": "3f81a0aa-e038-4c7d-f39b-ecb014da8454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 8s 4ms/step - loss: 1.8826 - accuracy: 0.3581\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4906 - accuracy: 0.4708\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3968 - accuracy: 0.5038\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3486 - accuracy: 0.5254\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3127 - accuracy: 0.5402\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2930 - accuracy: 0.5527\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2910 - accuracy: 0.5533\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2825 - accuracy: 0.5592\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2841 - accuracy: 0.5574\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2969 - accuracy: 0.5542\n",
            "[[0.01 0.01 0.09 0.07 0.26 0.09 0.39 0.08 0.   0.01]\n",
            " [0.   0.03 0.   0.   0.   0.   0.   0.   0.   0.96]\n",
            " [0.13 0.01 0.02 0.05 0.   0.04 0.   0.02 0.5  0.23]\n",
            " [0.01 0.   0.06 0.03 0.46 0.06 0.31 0.07 0.   0.  ]\n",
            " [0.   0.19 0.   0.   0.   0.   0.   0.   0.   0.81]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9\n",
              "0  0  0  0  0  0  0  1  0  0  0\n",
              "1  0  0  0  0  0  0  0  0  0  1\n",
              "2  0  0  0  0  0  0  0  0  0  1\n",
              "3  0  0  0  0  1  0  0  0  0  0\n",
              "4  0  1  0  0  0  0  0  0  0  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6b1cac4-56c0-479b-a1e6-a7fc60b12e5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6b1cac4-56c0-479b-a1e6-a7fc60b12e5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6b1cac4-56c0-479b-a1e6-a7fc60b12e5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6b1cac4-56c0-479b-a1e6-a7fc60b12e5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN 임포트\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN,Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import read_csv"
      ],
      "metadata": {
        "id": "3_iT_GOnQyiH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#usecol=사용할 칼럼. 즉 사용할 데이터를 의미\n",
        "#skipfooter=뒤에서 몇개 스킵할지 \n",
        "                                             #내가사용할 칼럼3번째임       끝에서 3개는 읽지 않음\n",
        "dataframe=read_csv('/content/corona_daily.csv',usecols=[3],engine='python',skipfooter=3)\n",
        "print(dataframe)#잘 읽혔는지 찍어봄\n",
        "\n",
        "#확진자 수만 필요\n",
        "dataset=dataframe.values #값들만 추출\n",
        "print(dataset)\n",
        "\n",
        "#정규화를 실시할 수 있도록 실수로 변경\n",
        "dataset=dataset.astype('float32')\n",
        "\n",
        "#MinMaxScaler 인스턴스 생성\n",
        "#데이터를 정규화하는 범위를 0~1 사이의 값으로\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "#MinMaxScaler 함수 중 fit_transform 함수를 사용하여 데이터를 실제로 정규화\n",
        "Dataset=scaler.fit_transform(dataset ) #생성된 인스턴스에 위에서 읽은 데이터셋 넣음\n",
        "\n",
        "#train_test_split 함수를 사용하여 전체 데이터를 훈련 데이터와 검증 데이터로 분류\n",
        "#비율은 8:2로 하고 섞지 않는다(shuffle=False)\n",
        "train_data,test_data=train_test_split(Dataset,test_size=0.2,shuffle=False)\n",
        "\n",
        "print(len(train_data),len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHr2CH8GRQZP",
        "outputId": "57354672-2289-4a89-9697-d99aa8ab2ebb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Confirmed\n",
            "0           24\n",
            "1           24\n",
            "2           27\n",
            "3           27\n",
            "4           28\n",
            "..         ...\n",
            "107      11190\n",
            "108      11206\n",
            "109      11225\n",
            "110      11265\n",
            "111      11344\n",
            "\n",
            "[112 rows x 1 columns]\n",
            "[[   24]\n",
            " [   24]\n",
            " [   27]\n",
            " [   27]\n",
            " [   28]\n",
            " [   28]\n",
            " [   28]\n",
            " [   28]\n",
            " [   28]\n",
            " [   29]\n",
            " [   30]\n",
            " [   31]\n",
            " [   51]\n",
            " [  104]\n",
            " [  204]\n",
            " [  433]\n",
            " [  602]\n",
            " [  833]\n",
            " [  977]\n",
            " [ 1261]\n",
            " [ 1766]\n",
            " [ 2337]\n",
            " [ 3150]\n",
            " [ 3736]\n",
            " [ 4212]\n",
            " [ 4812]\n",
            " [ 5328]\n",
            " [ 5766]\n",
            " [ 6284]\n",
            " [ 6767]\n",
            " [ 7134]\n",
            " [ 7382]\n",
            " [ 7513]\n",
            " [ 7755]\n",
            " [ 7869]\n",
            " [ 7979]\n",
            " [ 8086]\n",
            " [ 8162]\n",
            " [ 8236]\n",
            " [ 8320]\n",
            " [ 8413]\n",
            " [ 8565]\n",
            " [ 8652]\n",
            " [ 8799]\n",
            " [ 8897]\n",
            " [ 8961]\n",
            " [ 9037]\n",
            " [ 9137]\n",
            " [ 9241]\n",
            " [ 9332]\n",
            " [ 9478]\n",
            " [ 9583]\n",
            " [ 9661]\n",
            " [ 9786]\n",
            " [ 9887]\n",
            " [ 9976]\n",
            " [10062]\n",
            " [10156]\n",
            " [10237]\n",
            " [10284]\n",
            " [10331]\n",
            " [10384]\n",
            " [10423]\n",
            " [10450]\n",
            " [10480]\n",
            " [10512]\n",
            " [10537]\n",
            " [10564]\n",
            " [10591]\n",
            " [10613]\n",
            " [10635]\n",
            " [10653]\n",
            " [10661]\n",
            " [10674]\n",
            " [10683]\n",
            " [10694]\n",
            " [10702]\n",
            " [10708]\n",
            " [10718]\n",
            " [10728]\n",
            " [10738]\n",
            " [10752]\n",
            " [10761]\n",
            " [10765]\n",
            " [10774]\n",
            " [10780]\n",
            " [10793]\n",
            " [10801]\n",
            " [10804]\n",
            " [10806]\n",
            " [10810]\n",
            " [10822]\n",
            " [10840]\n",
            " [10874]\n",
            " [10909]\n",
            " [10936]\n",
            " [10962]\n",
            " [10991]\n",
            " [11018]\n",
            " [11037]\n",
            " [11050]\n",
            " [11065]\n",
            " [11078]\n",
            " [11110]\n",
            " [11122]\n",
            " [11142]\n",
            " [11165]\n",
            " [11190]\n",
            " [11206]\n",
            " [11225]\n",
            " [11265]\n",
            " [11344]]\n",
            "89 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#두 번째 parameter는 몇일 전 것까지 참고할지\n",
        "#본 예에서는 3일치를 바탕으로 예측\n",
        "def create_dataset(dataset,look_back):\n",
        "  x_data=[]\n",
        "  y_data=[]\n",
        "\n",
        "  #전체 데이터가 10개라면 총 7번을 반복\n",
        "  for i in range(len(dataset)-look_back):\n",
        "\n",
        "    #1일차부터 3일차까지의 데이터를 뽑아야 하기 때문에 dataset[0:3,0]\n",
        "    #데이터를 추출할 때 확진자 수를 나타내는 첫 번째 열(0번째 열)에서만 추출하기 때문에 숫자0\n",
        "    #두 번째로, 2일차 부터 4일차 까지의 데이터를 뽑아야 하므로 dataset(1:4,0)등 반복\n",
        "    data=dataset[i:(i+look_back),0]\n",
        "\n",
        "    #추출한 3개의 연속된 데이터를 x_data 배열에 넣고,\n",
        "    #연속된 데이터의 이후 값을 y_data배열에 넣어줌\n",
        "    x_data.append(data)\n",
        "    y_data.append(dataset[i+look_back,0])\n",
        "\n",
        "  return np.array(x_data),np.array(y_data)  \n",
        "  "
      ],
      "metadata": {
        "id": "5KBmtMEXYape"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#며칠 동안의 연속된 데이터를 바탕으로 학습할지\n",
        "look_back=3\n",
        "\n",
        "#훈련 데이터를 함수를 통해 2개의 데이터 생성(x_data,y_data)\n",
        "x_train,y_train=create_dataset(train_data,look_back)\n",
        "\n",
        "#검증 데이터를 함수를 통해 2개의 데이터 생성(x_data,y_data)\n",
        "x_test,y_test=create_dataset(test_data,look_back)\n",
        "\n",
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)\n",
        "\n",
        "print(train_data)\n",
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVDH8r7ubHJG",
        "outputId": "30fcbeb9-b3cd-4fbb-e113-043095b6f8de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(86, 3) (86,)\n",
            "(20, 3) (20,)\n",
            "[[0.0000000e+00]\n",
            " [0.0000000e+00]\n",
            " [2.6501762e-04]\n",
            " [2.6501762e-04]\n",
            " [3.5335682e-04]\n",
            " [3.5335682e-04]\n",
            " [3.5335682e-04]\n",
            " [3.5335682e-04]\n",
            " [3.5335682e-04]\n",
            " [4.4169603e-04]\n",
            " [5.3003523e-04]\n",
            " [6.1837444e-04]\n",
            " [2.3851590e-03]\n",
            " [7.0671379e-03]\n",
            " [1.5901061e-02]\n",
            " [3.6130741e-02]\n",
            " [5.1060069e-02]\n",
            " [7.1466424e-02]\n",
            " [8.4187277e-02]\n",
            " [1.0927561e-01]\n",
            " [1.5388693e-01]\n",
            " [2.0432863e-01]\n",
            " [2.7614841e-01]\n",
            " [3.2791519e-01]\n",
            " [3.6996466e-01]\n",
            " [4.2296818e-01]\n",
            " [4.6855122e-01]\n",
            " [5.0724381e-01]\n",
            " [5.5300355e-01]\n",
            " [5.9567136e-01]\n",
            " [6.2809187e-01]\n",
            " [6.4999998e-01]\n",
            " [6.6157240e-01]\n",
            " [6.8295050e-01]\n",
            " [6.9302118e-01]\n",
            " [7.0273852e-01]\n",
            " [7.1219081e-01]\n",
            " [7.1890455e-01]\n",
            " [7.2544169e-01]\n",
            " [7.3286217e-01]\n",
            " [7.4107772e-01]\n",
            " [7.5450528e-01]\n",
            " [7.6219082e-01]\n",
            " [7.7517664e-01]\n",
            " [7.8383392e-01]\n",
            " [7.8948760e-01]\n",
            " [7.9620141e-01]\n",
            " [8.0503529e-01]\n",
            " [8.1422257e-01]\n",
            " [8.2226145e-01]\n",
            " [8.3515900e-01]\n",
            " [8.4443462e-01]\n",
            " [8.5132509e-01]\n",
            " [8.6236745e-01]\n",
            " [8.7128973e-01]\n",
            " [8.7915194e-01]\n",
            " [8.8674909e-01]\n",
            " [8.9505297e-01]\n",
            " [9.0220845e-01]\n",
            " [9.0636039e-01]\n",
            " [9.1051233e-01]\n",
            " [9.1519433e-01]\n",
            " [9.1863954e-01]\n",
            " [9.2102474e-01]\n",
            " [9.2367488e-01]\n",
            " [9.2650175e-01]\n",
            " [9.2871022e-01]\n",
            " [9.3109536e-01]\n",
            " [9.3348056e-01]\n",
            " [9.3542403e-01]\n",
            " [9.3736750e-01]\n",
            " [9.3895757e-01]\n",
            " [9.3966430e-01]\n",
            " [9.4081271e-01]\n",
            " [9.4160777e-01]\n",
            " [9.4257951e-01]\n",
            " [9.4328618e-01]\n",
            " [9.4381624e-01]\n",
            " [9.4469965e-01]\n",
            " [9.4558305e-01]\n",
            " [9.4646639e-01]\n",
            " [9.4770318e-01]\n",
            " [9.4849819e-01]\n",
            " [9.4885159e-01]\n",
            " [9.4964665e-01]\n",
            " [9.5017666e-01]\n",
            " [9.5132506e-01]\n",
            " [9.5203179e-01]\n",
            " [9.5229679e-01]]\n",
            "[[0.0000000e+00 0.0000000e+00 2.6501762e-04]\n",
            " [0.0000000e+00 2.6501762e-04 2.6501762e-04]\n",
            " [2.6501762e-04 2.6501762e-04 3.5335682e-04]\n",
            " [2.6501762e-04 3.5335682e-04 3.5335682e-04]\n",
            " [3.5335682e-04 3.5335682e-04 3.5335682e-04]\n",
            " [3.5335682e-04 3.5335682e-04 3.5335682e-04]\n",
            " [3.5335682e-04 3.5335682e-04 3.5335682e-04]\n",
            " [3.5335682e-04 3.5335682e-04 4.4169603e-04]\n",
            " [3.5335682e-04 4.4169603e-04 5.3003523e-04]\n",
            " [4.4169603e-04 5.3003523e-04 6.1837444e-04]\n",
            " [5.3003523e-04 6.1837444e-04 2.3851590e-03]\n",
            " [6.1837444e-04 2.3851590e-03 7.0671379e-03]\n",
            " [2.3851590e-03 7.0671379e-03 1.5901061e-02]\n",
            " [7.0671379e-03 1.5901061e-02 3.6130741e-02]\n",
            " [1.5901061e-02 3.6130741e-02 5.1060069e-02]\n",
            " [3.6130741e-02 5.1060069e-02 7.1466424e-02]\n",
            " [5.1060069e-02 7.1466424e-02 8.4187277e-02]\n",
            " [7.1466424e-02 8.4187277e-02 1.0927561e-01]\n",
            " [8.4187277e-02 1.0927561e-01 1.5388693e-01]\n",
            " [1.0927561e-01 1.5388693e-01 2.0432863e-01]\n",
            " [1.5388693e-01 2.0432863e-01 2.7614841e-01]\n",
            " [2.0432863e-01 2.7614841e-01 3.2791519e-01]\n",
            " [2.7614841e-01 3.2791519e-01 3.6996466e-01]\n",
            " [3.2791519e-01 3.6996466e-01 4.2296818e-01]\n",
            " [3.6996466e-01 4.2296818e-01 4.6855122e-01]\n",
            " [4.2296818e-01 4.6855122e-01 5.0724381e-01]\n",
            " [4.6855122e-01 5.0724381e-01 5.5300355e-01]\n",
            " [5.0724381e-01 5.5300355e-01 5.9567136e-01]\n",
            " [5.5300355e-01 5.9567136e-01 6.2809187e-01]\n",
            " [5.9567136e-01 6.2809187e-01 6.4999998e-01]\n",
            " [6.2809187e-01 6.4999998e-01 6.6157240e-01]\n",
            " [6.4999998e-01 6.6157240e-01 6.8295050e-01]\n",
            " [6.6157240e-01 6.8295050e-01 6.9302118e-01]\n",
            " [6.8295050e-01 6.9302118e-01 7.0273852e-01]\n",
            " [6.9302118e-01 7.0273852e-01 7.1219081e-01]\n",
            " [7.0273852e-01 7.1219081e-01 7.1890455e-01]\n",
            " [7.1219081e-01 7.1890455e-01 7.2544169e-01]\n",
            " [7.1890455e-01 7.2544169e-01 7.3286217e-01]\n",
            " [7.2544169e-01 7.3286217e-01 7.4107772e-01]\n",
            " [7.3286217e-01 7.4107772e-01 7.5450528e-01]\n",
            " [7.4107772e-01 7.5450528e-01 7.6219082e-01]\n",
            " [7.5450528e-01 7.6219082e-01 7.7517664e-01]\n",
            " [7.6219082e-01 7.7517664e-01 7.8383392e-01]\n",
            " [7.7517664e-01 7.8383392e-01 7.8948760e-01]\n",
            " [7.8383392e-01 7.8948760e-01 7.9620141e-01]\n",
            " [7.8948760e-01 7.9620141e-01 8.0503529e-01]\n",
            " [7.9620141e-01 8.0503529e-01 8.1422257e-01]\n",
            " [8.0503529e-01 8.1422257e-01 8.2226145e-01]\n",
            " [8.1422257e-01 8.2226145e-01 8.3515900e-01]\n",
            " [8.2226145e-01 8.3515900e-01 8.4443462e-01]\n",
            " [8.3515900e-01 8.4443462e-01 8.5132509e-01]\n",
            " [8.4443462e-01 8.5132509e-01 8.6236745e-01]\n",
            " [8.5132509e-01 8.6236745e-01 8.7128973e-01]\n",
            " [8.6236745e-01 8.7128973e-01 8.7915194e-01]\n",
            " [8.7128973e-01 8.7915194e-01 8.8674909e-01]\n",
            " [8.7915194e-01 8.8674909e-01 8.9505297e-01]\n",
            " [8.8674909e-01 8.9505297e-01 9.0220845e-01]\n",
            " [8.9505297e-01 9.0220845e-01 9.0636039e-01]\n",
            " [9.0220845e-01 9.0636039e-01 9.1051233e-01]\n",
            " [9.0636039e-01 9.1051233e-01 9.1519433e-01]\n",
            " [9.1051233e-01 9.1519433e-01 9.1863954e-01]\n",
            " [9.1519433e-01 9.1863954e-01 9.2102474e-01]\n",
            " [9.1863954e-01 9.2102474e-01 9.2367488e-01]\n",
            " [9.2102474e-01 9.2367488e-01 9.2650175e-01]\n",
            " [9.2367488e-01 9.2650175e-01 9.2871022e-01]\n",
            " [9.2650175e-01 9.2871022e-01 9.3109536e-01]\n",
            " [9.2871022e-01 9.3109536e-01 9.3348056e-01]\n",
            " [9.3109536e-01 9.3348056e-01 9.3542403e-01]\n",
            " [9.3348056e-01 9.3542403e-01 9.3736750e-01]\n",
            " [9.3542403e-01 9.3736750e-01 9.3895757e-01]\n",
            " [9.3736750e-01 9.3895757e-01 9.3966430e-01]\n",
            " [9.3895757e-01 9.3966430e-01 9.4081271e-01]\n",
            " [9.3966430e-01 9.4081271e-01 9.4160777e-01]\n",
            " [9.4081271e-01 9.4160777e-01 9.4257951e-01]\n",
            " [9.4160777e-01 9.4257951e-01 9.4328618e-01]\n",
            " [9.4257951e-01 9.4328618e-01 9.4381624e-01]\n",
            " [9.4328618e-01 9.4381624e-01 9.4469965e-01]\n",
            " [9.4381624e-01 9.4469965e-01 9.4558305e-01]\n",
            " [9.4469965e-01 9.4558305e-01 9.4646639e-01]\n",
            " [9.4558305e-01 9.4646639e-01 9.4770318e-01]\n",
            " [9.4646639e-01 9.4770318e-01 9.4849819e-01]\n",
            " [9.4770318e-01 9.4849819e-01 9.4885159e-01]\n",
            " [9.4849819e-01 9.4885159e-01 9.4964665e-01]\n",
            " [9.4885159e-01 9.4964665e-01 9.5017666e-01]\n",
            " [9.4964665e-01 9.5017666e-01 9.5132506e-01]\n",
            " [9.5017666e-01 9.5132506e-01 9.5203179e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 포맷 변환\n",
        "#x_trian(86,3)을 (86,1,3)으로 reshape\n",
        "#x_test(20,3)을 (20,1,3)으로 reshape\n",
        "X_train=np.reshape(x_train,(x_train.shape[0],1,x_train.shape[1]))\n",
        "X_test=np.reshape(x_test,(x_test.shape[0],1,x_test.shape[1]))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print(x_test)\n",
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS5onLc1cniv",
        "outputId": "5d6ac220-1175-45a0-a62f-c31fd7d6818d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(86, 1, 3)\n",
            "(20, 1, 3)\n",
            "[[0.95247346 0.95282686 0.9538869 ]\n",
            " [0.95282686 0.9538869  0.955477  ]\n",
            " [0.9538869  0.955477   0.95848054]\n",
            " [0.955477   0.95848054 0.9615724 ]\n",
            " [0.95848054 0.9615724  0.96395755]\n",
            " [0.9615724  0.96395755 0.9662544 ]\n",
            " [0.96395755 0.9662544  0.9688162 ]\n",
            " [0.9662544  0.9688162  0.9712014 ]\n",
            " [0.9688162  0.9712014  0.9728798 ]\n",
            " [0.9712014  0.9728798  0.9740282 ]\n",
            " [0.9728798  0.9740282  0.97535336]\n",
            " [0.9740282  0.97535336 0.97650176]\n",
            " [0.97535336 0.97650176 0.9793286 ]\n",
            " [0.97650176 0.9793286  0.9803887 ]\n",
            " [0.9793286  0.9803887  0.98215544]\n",
            " [0.9803887  0.98215544 0.98418725]\n",
            " [0.98215544 0.98418725 0.9863957 ]\n",
            " [0.98418725 0.9863957  0.9878092 ]\n",
            " [0.9863957  0.9878092  0.9894876 ]\n",
            " [0.9878092  0.9894876  0.9930212 ]]\n",
            "[[[0.95247346 0.95282686 0.9538869 ]]\n",
            "\n",
            " [[0.95282686 0.9538869  0.955477  ]]\n",
            "\n",
            " [[0.9538869  0.955477   0.95848054]]\n",
            "\n",
            " [[0.955477   0.95848054 0.9615724 ]]\n",
            "\n",
            " [[0.95848054 0.9615724  0.96395755]]\n",
            "\n",
            " [[0.9615724  0.96395755 0.9662544 ]]\n",
            "\n",
            " [[0.96395755 0.9662544  0.9688162 ]]\n",
            "\n",
            " [[0.9662544  0.9688162  0.9712014 ]]\n",
            "\n",
            " [[0.9688162  0.9712014  0.9728798 ]]\n",
            "\n",
            " [[0.9712014  0.9728798  0.9740282 ]]\n",
            "\n",
            " [[0.9728798  0.9740282  0.97535336]]\n",
            "\n",
            " [[0.9740282  0.97535336 0.97650176]]\n",
            "\n",
            " [[0.97535336 0.97650176 0.9793286 ]]\n",
            "\n",
            " [[0.97650176 0.9793286  0.9803887 ]]\n",
            "\n",
            " [[0.9793286  0.9803887  0.98215544]]\n",
            "\n",
            " [[0.9803887  0.98215544 0.98418725]]\n",
            "\n",
            " [[0.98215544 0.98418725 0.9863957 ]]\n",
            "\n",
            " [[0.98418725 0.9863957  0.9878092 ]]\n",
            "\n",
            " [[0.9863957  0.9878092  0.9894876 ]]\n",
            "\n",
            " [[0.9878092  0.9894876  0.9930212 ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#과제\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "#데이터 준비\n",
        "(Xdata,Ydata),_=tf.keras.datasets.mnist.load_data()\n",
        "Xdata=Xdata.reshape(60000,28,28,1)\n",
        "Ydata=pd.get_dummies(Ydata)\n",
        "\n",
        "#모델 생성\n",
        "X=tf.keras.layers.Input(shape=[28,28,1]) \n",
        "                  \n",
        "H=tf.keras.layers.Conv2D(6,kernel_size=5, padding='same',activation='swish')(X)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=tf.keras.layers.Conv2D(16,kernel_size=6,activation='swish')(H)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=tf.keras.layers.Flatten()(H)\n",
        "H=tf.keras.layers.Dense(100,activation='swish')(H)\n",
        "H=tf.keras.layers.Dense(80,activation='swish')(H)\n",
        "Y=tf.keras.layers.Dense(10,activation='softmax')(H) \n",
        "\n",
        "model=tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='categorical_crossentropy',metrics='accuracy')\n",
        "\n",
        "#모델 학습\n",
        "model.fit(Xdata,Ydata,epochs=10)\n",
        "\n",
        "#모델 이용(예상) 및 정답확인\n",
        "pred=model.predict(Xdata[0:5])\n",
        "print(pred.round(2))\n",
        "Ydata[0:5]\n"
      ],
      "metadata": {
        "id": "Dgc-4G5JKOYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "outputId": "2741615f-4a86-4d68-f64c-d8153fdac026"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 26s 5ms/step - loss: 0.2789 - accuracy: 0.9302\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0858 - accuracy: 0.9767\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0746 - accuracy: 0.9821\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0664 - accuracy: 0.9835\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0631 - accuracy: 0.9852\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0637 - accuracy: 0.9855\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0624 - accuracy: 0.9862\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0651 - accuracy: 0.9865\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0681 - accuracy: 0.9863\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0719 - accuracy: 0.9862\n",
            "[[0.   0.   0.   0.   0.   1.   0.   0.   0.   0.  ]\n",
            " [1.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
            " [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.01 0.   0.   0.   0.   0.99]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9\n",
              "0  0  0  0  0  0  1  0  0  0  0\n",
              "1  1  0  0  0  0  0  0  0  0  0\n",
              "2  0  0  0  0  1  0  0  0  0  0\n",
              "3  0  1  0  0  0  0  0  0  0  0\n",
              "4  0  0  0  0  0  0  0  0  0  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-390a6ecc-75d3-47f4-8df5-9d4908e51d65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-390a6ecc-75d3-47f4-8df5-9d4908e51d65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-390a6ecc-75d3-47f4-8df5-9d4908e51d65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-390a6ecc-75d3-47f4-8df5-9d4908e51d65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN 레이어들이 선형으로 연결된 모습이라서 Sequential 모델로 설정\n",
        "model=Sequential()\n",
        "\n",
        "#RNN 기법 중 SimpleRNN 사용하고 뉴런 수는 3개(바꿔도 됨)\n",
        "#데이터 형태는(1,3)과 같은 형태\n",
        "model.add(SimpleRNN(3,input_shape=(1,look_back)))\n",
        "\n",
        "#최종 예측 값은 확진자의 수이므로 1개\n",
        "#활성화 함수는 사용하지 않음(=linear)\n",
        "model.add(Dense(1,activation='linear'))\n",
        "#손실 함수는 mse(평균 제곱 오차)로, 옵티마이저는 adam\n",
        "model.compile(loss='mse',optimizer='Adam')\n",
        "\n",
        "#반복 횟수(100), 한 번에 학습시킬 데이터의 양(batch_size=1)설정\n",
        "model.fit(X_train,y_train,epochs=90,batch_size=1,verbose=0) #verbose는 화면에 나오게해라\n",
        "model.fit(X_train,y_train,epochs=10,batch_size=1,verbose=1)"
      ],
      "metadata": {
        "id": "Cv-bl3Dw6J5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6491dc-f123-4849-cc0e-bc5a942823bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 3.3275e-04\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 3.1666e-04\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 3.2882e-04\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 3.0863e-04\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 3.3225e-04\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 3.2100e-04\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 3.4452e-04\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 3.1209e-04\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 3.0536e-04\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 3.0086e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b1e6b9cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 데이터(X_train)의 값을 모델에 넣어 값을 예측\n",
        "#검증 데이터(X_test)의 값을 모델에 넣어 값을 예측\n",
        "trainPredict=model.predict(X_train)\n",
        "testPredict=model.predict(X_test) #predict는 정규화가 되어있어서 다시 풀어야함(밑에서함)\n",
        "\n",
        "#훈련/검증 데이터의 예측값이 정규화된 것이므로 다시 돌림\n",
        "TrainPredict=scaler.inverse_transform(trainPredict)\n",
        "TestPredict=scaler.inverse_transform(testPredict)\n",
        "\n",
        "\n",
        "#실제 확진자수도 inverse로 다시 돌림\n",
        "Y_train=scaler.inverse_transform([y_train])\n",
        "Y_test=scaler.inverse_transform([y_test])\n",
        "\n",
        "print(TrainPredict[:20])\n",
        "print(Y_train[0][:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEJkKAO4E3mR",
        "outputId": "89811c3f-d1ba-4d9b-afee-88c865326a5c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 222.674  ]\n",
            " [ 221.24594]\n",
            " [ 223.35767]\n",
            " [ 222.88165]\n",
            " [ 223.2067 ]\n",
            " [ 223.2067 ]\n",
            " [ 223.2067 ]\n",
            " [ 224.34276]\n",
            " [ 225.0024 ]\n",
            " [ 225.98741]\n",
            " [ 248.5513 ]\n",
            " [ 299.52444]\n",
            " [ 394.2951 ]\n",
            " [ 623.6338 ]\n",
            " [ 739.6751 ]\n",
            " [ 999.0101 ]\n",
            " [1111.2883 ]\n",
            " [1446.392  ]\n",
            " [1933.8273 ]\n",
            " [2442.425  ]]\n",
            "[  27.00000082   28.00000066   28.00000066   28.00000066   28.00000066\n",
            "   28.00000066   29.00000049   30.00000033   31.00000016   51.00000214\n",
            "  104.00000395  204.00001384  433.00000247  602.00000099  832.99993658\n",
            "  976.9999972  1260.99992933 1766.00008335 2337.00011053 3150.00006622]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#empty_like는 주어진 어레이의 형태와 타입을 갖는 새로운 어레이 반환 후 초기화(아무값도 없게)\n",
        "trainPredictPlot=np.empty_like(dataset)\n",
        "trainPredictPlot[:,:]=np.nan\n",
        "#훈련 데이터를 예측한 결괏값의 첫 번째 값은 1일차의 확진자 수가 아니라\n",
        "#4일차의 확진자 수로 처음값(look_back)을 건너뛰어야 함\n",
        "trainPredictPlot[look_back:len(TrainPredict)+look_back]=TrainPredict #4번째부터 값이 들어가기 때문에 앞에 3까지\n",
        "                                                                     #lookback(건너뜀) 3부터 값 끝까지 채워라\n",
        "\n",
        "#TestPredict을 위해 새로운 어레이 만들고, 초기화 후 값 할당\n",
        "testPredictPlot=np.empty_like(dataset)\n",
        "testPredictPlot[:,:]=np.nan\n",
        "testPredictPlot[len(TrainPredict)+(look_back)*2:len(dataset)]=TestPredict\n",
        "\n",
        "#원래 데이터, 훈련/검증 데이터 각각 그림\n",
        "plt.plot(dataset,c='red')\n",
        "plt.plot(trainPredictPlot,c='green')\n",
        "plt.plot(testPredictPlot,c='blue')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#결과보기\n",
        "#빨간색은 1일치부터, 녹색은 4일치 부터 시작하기 때문에 둘이 시작점이 다름\n",
        "#중후반에 녹색 중간에 끊김은 데이터가 없어서 끊긴것!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "T0NA5cOpJGKa",
        "outputId": "5fdb183d-9be2-49ba-f255-eaab3fde7616"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "\n",
        "#1.데이터, 와인 데이터 로드\n",
        "df=pd.read_csv('/content/wine.csv',header=None)\n",
        "\n",
        "#와인의 속성은 X로 와인의 분류를 y로 저장, (.iloc):행번호로 선택하는 방법\n",
        "X=df.iloc[:,0:12]\n",
        "y=df.iloc[:,12]\n",
        "\n",
        "#학습셋과 테스트셋으로 나눔\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,shuffle=True)\n",
        "\n",
        "#2.모델 구조 설정\n",
        "model=Sequential()\n",
        "model.add(Dense(30,input_dim=12,activation='relu'))\n",
        "model.add(Dense(12,activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#3.모델학습\n",
        "#학습이 언제 자동 중단될지 설정\n",
        "#검증셋 오차(val_loss)가 20번 이상 낮아지지 않으면(patience),검사 조기 종료\n",
        "early_stopping_callback=EarlyStopping(monitor='val_loss',patience=20)\n",
        "\n",
        "#0.8x0.25=0.2\n",
        "history=model.fit(X_train,y_train,epochs=2000,batch_size=500,validation_split=0.25,\n",
        "                  verbose=1,callbacks=[early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB0SEhzQP0yK",
        "outputId": "7bce1698-7dea-446b-b059-9f9629f9e0b1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "8/8 [==============================] - 2s 29ms/step - loss: 0.7683 - accuracy: 0.7526 - val_loss: 0.4791 - val_accuracy: 0.7523\n",
            "Epoch 2/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4426 - accuracy: 0.7621 - val_loss: 0.4111 - val_accuracy: 0.7777\n",
            "Epoch 3/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3794 - accuracy: 0.7924 - val_loss: 0.3622 - val_accuracy: 0.7915\n",
            "Epoch 4/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3413 - accuracy: 0.8232 - val_loss: 0.3144 - val_accuracy: 0.8546\n",
            "Epoch 5/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3077 - accuracy: 0.8835 - val_loss: 0.2898 - val_accuracy: 0.8869\n",
            "Epoch 6/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2824 - accuracy: 0.8963 - val_loss: 0.2697 - val_accuracy: 0.8915\n",
            "Epoch 7/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2648 - accuracy: 0.9081 - val_loss: 0.2519 - val_accuracy: 0.9108\n",
            "Epoch 8/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2475 - accuracy: 0.9220 - val_loss: 0.2371 - val_accuracy: 0.9200\n",
            "Epoch 9/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2332 - accuracy: 0.9256 - val_loss: 0.2224 - val_accuracy: 0.9246\n",
            "Epoch 10/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2212 - accuracy: 0.9279 - val_loss: 0.2109 - val_accuracy: 0.9292\n",
            "Epoch 11/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2121 - accuracy: 0.9317 - val_loss: 0.2033 - val_accuracy: 0.9331\n",
            "Epoch 12/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2054 - accuracy: 0.9335 - val_loss: 0.1984 - val_accuracy: 0.9315\n",
            "Epoch 13/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2013 - accuracy: 0.9305 - val_loss: 0.1951 - val_accuracy: 0.9292\n",
            "Epoch 14/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1968 - accuracy: 0.9325 - val_loss: 0.1918 - val_accuracy: 0.9331\n",
            "Epoch 15/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1944 - accuracy: 0.9348 - val_loss: 0.1897 - val_accuracy: 0.9323\n",
            "Epoch 16/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1919 - accuracy: 0.9325 - val_loss: 0.1879 - val_accuracy: 0.9331\n",
            "Epoch 17/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1887 - accuracy: 0.9356 - val_loss: 0.1858 - val_accuracy: 0.9362\n",
            "Epoch 18/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1888 - accuracy: 0.9333 - val_loss: 0.1847 - val_accuracy: 0.9331\n",
            "Epoch 19/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1863 - accuracy: 0.9343 - val_loss: 0.1821 - val_accuracy: 0.9377\n",
            "Epoch 20/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1849 - accuracy: 0.9343 - val_loss: 0.1814 - val_accuracy: 0.9354\n",
            "Epoch 21/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1846 - accuracy: 0.9351 - val_loss: 0.1789 - val_accuracy: 0.9377\n",
            "Epoch 22/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1829 - accuracy: 0.9343 - val_loss: 0.1776 - val_accuracy: 0.9354\n",
            "Epoch 23/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1816 - accuracy: 0.9371 - val_loss: 0.1763 - val_accuracy: 0.9362\n",
            "Epoch 24/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1802 - accuracy: 0.9356 - val_loss: 0.1746 - val_accuracy: 0.9369\n",
            "Epoch 25/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1792 - accuracy: 0.9366 - val_loss: 0.1732 - val_accuracy: 0.9385\n",
            "Epoch 26/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1778 - accuracy: 0.9369 - val_loss: 0.1720 - val_accuracy: 0.9377\n",
            "Epoch 27/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1785 - accuracy: 0.9351 - val_loss: 0.1727 - val_accuracy: 0.9369\n",
            "Epoch 28/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1774 - accuracy: 0.9379 - val_loss: 0.1710 - val_accuracy: 0.9392\n",
            "Epoch 29/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1767 - accuracy: 0.9369 - val_loss: 0.1727 - val_accuracy: 0.9354\n",
            "Epoch 30/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1789 - accuracy: 0.9366 - val_loss: 0.1690 - val_accuracy: 0.9385\n",
            "Epoch 31/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1727 - accuracy: 0.9379 - val_loss: 0.1673 - val_accuracy: 0.9377\n",
            "Epoch 32/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1724 - accuracy: 0.9387 - val_loss: 0.1649 - val_accuracy: 0.9400\n",
            "Epoch 33/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1721 - accuracy: 0.9384 - val_loss: 0.1641 - val_accuracy: 0.9400\n",
            "Epoch 34/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1711 - accuracy: 0.9397 - val_loss: 0.1635 - val_accuracy: 0.9392\n",
            "Epoch 35/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1695 - accuracy: 0.9405 - val_loss: 0.1613 - val_accuracy: 0.9400\n",
            "Epoch 36/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1680 - accuracy: 0.9400 - val_loss: 0.1596 - val_accuracy: 0.9415\n",
            "Epoch 37/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1656 - accuracy: 0.9415 - val_loss: 0.1599 - val_accuracy: 0.9400\n",
            "Epoch 38/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1663 - accuracy: 0.9405 - val_loss: 0.1593 - val_accuracy: 0.9415\n",
            "Epoch 39/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1638 - accuracy: 0.9418 - val_loss: 0.1571 - val_accuracy: 0.9431\n",
            "Epoch 40/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1621 - accuracy: 0.9425 - val_loss: 0.1534 - val_accuracy: 0.9446\n",
            "Epoch 41/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1602 - accuracy: 0.9441 - val_loss: 0.1533 - val_accuracy: 0.9454\n",
            "Epoch 42/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1592 - accuracy: 0.9435 - val_loss: 0.1525 - val_accuracy: 0.9462\n",
            "Epoch 43/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1578 - accuracy: 0.9446 - val_loss: 0.1491 - val_accuracy: 0.9462\n",
            "Epoch 44/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1552 - accuracy: 0.9448 - val_loss: 0.1475 - val_accuracy: 0.9454\n",
            "Epoch 45/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1540 - accuracy: 0.9456 - val_loss: 0.1490 - val_accuracy: 0.9523\n",
            "Epoch 46/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1527 - accuracy: 0.9453 - val_loss: 0.1482 - val_accuracy: 0.9446\n",
            "Epoch 47/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1515 - accuracy: 0.9469 - val_loss: 0.1439 - val_accuracy: 0.9485\n",
            "Epoch 48/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1495 - accuracy: 0.9466 - val_loss: 0.1435 - val_accuracy: 0.9492\n",
            "Epoch 49/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1475 - accuracy: 0.9469 - val_loss: 0.1419 - val_accuracy: 0.9485\n",
            "Epoch 50/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1458 - accuracy: 0.9477 - val_loss: 0.1397 - val_accuracy: 0.9531\n",
            "Epoch 51/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1457 - accuracy: 0.9484 - val_loss: 0.1389 - val_accuracy: 0.9500\n",
            "Epoch 52/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1436 - accuracy: 0.9479 - val_loss: 0.1370 - val_accuracy: 0.9508\n",
            "Epoch 53/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.9502 - val_loss: 0.1355 - val_accuracy: 0.9554\n",
            "Epoch 54/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1395 - accuracy: 0.9489 - val_loss: 0.1341 - val_accuracy: 0.9500\n",
            "Epoch 55/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1371 - accuracy: 0.9479 - val_loss: 0.1285 - val_accuracy: 0.9554\n",
            "Epoch 56/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1338 - accuracy: 0.9518 - val_loss: 0.1290 - val_accuracy: 0.9508\n",
            "Epoch 57/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1331 - accuracy: 0.9507 - val_loss: 0.1259 - val_accuracy: 0.9546\n",
            "Epoch 58/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1306 - accuracy: 0.9528 - val_loss: 0.1237 - val_accuracy: 0.9554\n",
            "Epoch 59/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1312 - accuracy: 0.9510 - val_loss: 0.1232 - val_accuracy: 0.9592\n",
            "Epoch 60/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1297 - accuracy: 0.9541 - val_loss: 0.1339 - val_accuracy: 0.9592\n",
            "Epoch 61/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1307 - accuracy: 0.9523 - val_loss: 0.1261 - val_accuracy: 0.9600\n",
            "Epoch 62/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1281 - accuracy: 0.9518 - val_loss: 0.1200 - val_accuracy: 0.9592\n",
            "Epoch 63/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1261 - accuracy: 0.9564 - val_loss: 0.1210 - val_accuracy: 0.9546\n",
            "Epoch 64/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1219 - accuracy: 0.9561 - val_loss: 0.1176 - val_accuracy: 0.9554\n",
            "Epoch 65/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1197 - accuracy: 0.9559 - val_loss: 0.1170 - val_accuracy: 0.9562\n",
            "Epoch 66/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1200 - accuracy: 0.9554 - val_loss: 0.1156 - val_accuracy: 0.9585\n",
            "Epoch 67/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1190 - accuracy: 0.9551 - val_loss: 0.1139 - val_accuracy: 0.9592\n",
            "Epoch 68/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1183 - accuracy: 0.9566 - val_loss: 0.1146 - val_accuracy: 0.9623\n",
            "Epoch 69/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1154 - accuracy: 0.9582 - val_loss: 0.1120 - val_accuracy: 0.9608\n",
            "Epoch 70/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1135 - accuracy: 0.9592 - val_loss: 0.1109 - val_accuracy: 0.9608\n",
            "Epoch 71/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1123 - accuracy: 0.9587 - val_loss: 0.1108 - val_accuracy: 0.9608\n",
            "Epoch 72/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1123 - accuracy: 0.9592 - val_loss: 0.1093 - val_accuracy: 0.9615\n",
            "Epoch 73/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1102 - accuracy: 0.9592 - val_loss: 0.1087 - val_accuracy: 0.9638\n",
            "Epoch 74/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1090 - accuracy: 0.9602 - val_loss: 0.1078 - val_accuracy: 0.9615\n",
            "Epoch 75/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1081 - accuracy: 0.9613 - val_loss: 0.1074 - val_accuracy: 0.9608\n",
            "Epoch 76/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1067 - accuracy: 0.9613 - val_loss: 0.1076 - val_accuracy: 0.9654\n",
            "Epoch 77/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1068 - accuracy: 0.9618 - val_loss: 0.1074 - val_accuracy: 0.9662\n",
            "Epoch 78/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1066 - accuracy: 0.9623 - val_loss: 0.1066 - val_accuracy: 0.9677\n",
            "Epoch 79/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1096 - accuracy: 0.9610 - val_loss: 0.1063 - val_accuracy: 0.9677\n",
            "Epoch 80/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1098 - accuracy: 0.9605 - val_loss: 0.1032 - val_accuracy: 0.9662\n",
            "Epoch 81/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1044 - accuracy: 0.9633 - val_loss: 0.1045 - val_accuracy: 0.9623\n",
            "Epoch 82/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1037 - accuracy: 0.9636 - val_loss: 0.1023 - val_accuracy: 0.9631\n",
            "Epoch 83/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1028 - accuracy: 0.9643 - val_loss: 0.1010 - val_accuracy: 0.9662\n",
            "Epoch 84/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1011 - accuracy: 0.9625 - val_loss: 0.1005 - val_accuracy: 0.9662\n",
            "Epoch 85/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0995 - accuracy: 0.9648 - val_loss: 0.1008 - val_accuracy: 0.9677\n",
            "Epoch 86/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0990 - accuracy: 0.9651 - val_loss: 0.1006 - val_accuracy: 0.9692\n",
            "Epoch 87/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0989 - accuracy: 0.9643 - val_loss: 0.0986 - val_accuracy: 0.9685\n",
            "Epoch 88/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0987 - accuracy: 0.9648 - val_loss: 0.0978 - val_accuracy: 0.9669\n",
            "Epoch 89/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0993 - accuracy: 0.9651 - val_loss: 0.0982 - val_accuracy: 0.9669\n",
            "Epoch 90/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0989 - accuracy: 0.9669 - val_loss: 0.1020 - val_accuracy: 0.9623\n",
            "Epoch 91/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1028 - accuracy: 0.9623 - val_loss: 0.1083 - val_accuracy: 0.9585\n",
            "Epoch 92/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1033 - accuracy: 0.9659 - val_loss: 0.1019 - val_accuracy: 0.9631\n",
            "Epoch 93/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1001 - accuracy: 0.9638 - val_loss: 0.0951 - val_accuracy: 0.9700\n",
            "Epoch 94/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0942 - accuracy: 0.9684 - val_loss: 0.0953 - val_accuracy: 0.9700\n",
            "Epoch 95/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0938 - accuracy: 0.9684 - val_loss: 0.0937 - val_accuracy: 0.9700\n",
            "Epoch 96/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0948 - accuracy: 0.9687 - val_loss: 0.0921 - val_accuracy: 0.9708\n",
            "Epoch 97/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0920 - accuracy: 0.9713 - val_loss: 0.0919 - val_accuracy: 0.9700\n",
            "Epoch 98/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0916 - accuracy: 0.9702 - val_loss: 0.0913 - val_accuracy: 0.9700\n",
            "Epoch 99/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0922 - accuracy: 0.9695 - val_loss: 0.0918 - val_accuracy: 0.9692\n",
            "Epoch 100/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0934 - accuracy: 0.9697 - val_loss: 0.0904 - val_accuracy: 0.9700\n",
            "Epoch 101/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0912 - accuracy: 0.9697 - val_loss: 0.0927 - val_accuracy: 0.9754\n",
            "Epoch 102/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0923 - accuracy: 0.9702 - val_loss: 0.0941 - val_accuracy: 0.9731\n",
            "Epoch 103/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0907 - accuracy: 0.9723 - val_loss: 0.0890 - val_accuracy: 0.9723\n",
            "Epoch 104/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0887 - accuracy: 0.9713 - val_loss: 0.0933 - val_accuracy: 0.9731\n",
            "Epoch 105/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0892 - accuracy: 0.9692 - val_loss: 0.0876 - val_accuracy: 0.9723\n",
            "Epoch 106/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0900 - accuracy: 0.9720 - val_loss: 0.0872 - val_accuracy: 0.9715\n",
            "Epoch 107/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 0.9720 - val_loss: 0.0868 - val_accuracy: 0.9738\n",
            "Epoch 108/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0866 - accuracy: 0.9718 - val_loss: 0.0876 - val_accuracy: 0.9754\n",
            "Epoch 109/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0859 - accuracy: 0.9728 - val_loss: 0.0855 - val_accuracy: 0.9746\n",
            "Epoch 110/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0856 - accuracy: 0.9731 - val_loss: 0.0851 - val_accuracy: 0.9746\n",
            "Epoch 111/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0849 - accuracy: 0.9720 - val_loss: 0.0850 - val_accuracy: 0.9769\n",
            "Epoch 112/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0869 - accuracy: 0.9725 - val_loss: 0.0847 - val_accuracy: 0.9723\n",
            "Epoch 113/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0865 - accuracy: 0.9720 - val_loss: 0.0876 - val_accuracy: 0.9692\n",
            "Epoch 114/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0850 - accuracy: 0.9738 - val_loss: 0.0830 - val_accuracy: 0.9746\n",
            "Epoch 115/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0841 - accuracy: 0.9749 - val_loss: 0.0838 - val_accuracy: 0.9715\n",
            "Epoch 116/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9720 - val_loss: 0.0828 - val_accuracy: 0.9785\n",
            "Epoch 117/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9756 - val_loss: 0.0897 - val_accuracy: 0.9746\n",
            "Epoch 118/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0852 - accuracy: 0.9741 - val_loss: 0.0816 - val_accuracy: 0.9754\n",
            "Epoch 119/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9731 - val_loss: 0.0825 - val_accuracy: 0.9708\n",
            "Epoch 120/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0851 - accuracy: 0.9741 - val_loss: 0.0810 - val_accuracy: 0.9731\n",
            "Epoch 121/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0816 - accuracy: 0.9725 - val_loss: 0.0800 - val_accuracy: 0.9785\n",
            "Epoch 122/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0813 - accuracy: 0.9741 - val_loss: 0.0800 - val_accuracy: 0.9785\n",
            "Epoch 123/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9733 - val_loss: 0.0799 - val_accuracy: 0.9792\n",
            "Epoch 124/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0812 - accuracy: 0.9743 - val_loss: 0.0826 - val_accuracy: 0.9785\n",
            "Epoch 125/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0808 - accuracy: 0.9749 - val_loss: 0.0860 - val_accuracy: 0.9746\n",
            "Epoch 126/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0810 - accuracy: 0.9728 - val_loss: 0.0776 - val_accuracy: 0.9777\n",
            "Epoch 127/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0800 - accuracy: 0.9756 - val_loss: 0.0773 - val_accuracy: 0.9777\n",
            "Epoch 128/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0799 - accuracy: 0.9759 - val_loss: 0.0765 - val_accuracy: 0.9785\n",
            "Epoch 129/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0782 - accuracy: 0.9769 - val_loss: 0.0779 - val_accuracy: 0.9746\n",
            "Epoch 130/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0791 - accuracy: 0.9761 - val_loss: 0.0763 - val_accuracy: 0.9762\n",
            "Epoch 131/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0773 - accuracy: 0.9764 - val_loss: 0.0758 - val_accuracy: 0.9769\n",
            "Epoch 132/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0766 - accuracy: 0.9761 - val_loss: 0.0757 - val_accuracy: 0.9800\n",
            "Epoch 133/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0766 - accuracy: 0.9777 - val_loss: 0.0751 - val_accuracy: 0.9746\n",
            "Epoch 134/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0770 - accuracy: 0.9766 - val_loss: 0.0739 - val_accuracy: 0.9800\n",
            "Epoch 135/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0754 - accuracy: 0.9764 - val_loss: 0.0743 - val_accuracy: 0.9762\n",
            "Epoch 136/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0759 - accuracy: 0.9766 - val_loss: 0.0732 - val_accuracy: 0.9792\n",
            "Epoch 137/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0750 - accuracy: 0.9764 - val_loss: 0.0736 - val_accuracy: 0.9800\n",
            "Epoch 138/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0744 - accuracy: 0.9779 - val_loss: 0.0739 - val_accuracy: 0.9762\n",
            "Epoch 139/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0800 - accuracy: 0.9738 - val_loss: 0.0732 - val_accuracy: 0.9754\n",
            "Epoch 140/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0796 - accuracy: 0.9733 - val_loss: 0.0719 - val_accuracy: 0.9800\n",
            "Epoch 141/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0789 - accuracy: 0.9754 - val_loss: 0.0729 - val_accuracy: 0.9800\n",
            "Epoch 142/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0762 - accuracy: 0.9756 - val_loss: 0.0743 - val_accuracy: 0.9792\n",
            "Epoch 143/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0750 - accuracy: 0.9769 - val_loss: 0.0730 - val_accuracy: 0.9800\n",
            "Epoch 144/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0774 - accuracy: 0.9759 - val_loss: 0.0725 - val_accuracy: 0.9800\n",
            "Epoch 145/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0743 - accuracy: 0.9774 - val_loss: 0.0709 - val_accuracy: 0.9808\n",
            "Epoch 146/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0728 - accuracy: 0.9777 - val_loss: 0.0696 - val_accuracy: 0.9800\n",
            "Epoch 147/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0730 - accuracy: 0.9779 - val_loss: 0.0726 - val_accuracy: 0.9785\n",
            "Epoch 148/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0736 - accuracy: 0.9764 - val_loss: 0.0686 - val_accuracy: 0.9808\n",
            "Epoch 149/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0740 - accuracy: 0.9756 - val_loss: 0.0684 - val_accuracy: 0.9808\n",
            "Epoch 150/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0729 - accuracy: 0.9777 - val_loss: 0.0681 - val_accuracy: 0.9823\n",
            "Epoch 151/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0726 - accuracy: 0.9779 - val_loss: 0.0677 - val_accuracy: 0.9815\n",
            "Epoch 152/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0727 - accuracy: 0.9772 - val_loss: 0.0675 - val_accuracy: 0.9815\n",
            "Epoch 153/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0712 - accuracy: 0.9777 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
            "Epoch 154/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0754 - accuracy: 0.9743 - val_loss: 0.0742 - val_accuracy: 0.9777\n",
            "Epoch 155/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0724 - accuracy: 0.9787 - val_loss: 0.0667 - val_accuracy: 0.9823\n",
            "Epoch 156/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0758 - accuracy: 0.9751 - val_loss: 0.0688 - val_accuracy: 0.9800\n",
            "Epoch 157/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0731 - accuracy: 0.9777 - val_loss: 0.0772 - val_accuracy: 0.9715\n",
            "Epoch 158/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0769 - accuracy: 0.9761 - val_loss: 0.0657 - val_accuracy: 0.9808\n",
            "Epoch 159/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0751 - accuracy: 0.9759 - val_loss: 0.0651 - val_accuracy: 0.9815\n",
            "Epoch 160/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0701 - accuracy: 0.9790 - val_loss: 0.0727 - val_accuracy: 0.9769\n",
            "Epoch 161/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0697 - accuracy: 0.9805 - val_loss: 0.0645 - val_accuracy: 0.9823\n",
            "Epoch 162/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0686 - accuracy: 0.9797 - val_loss: 0.0637 - val_accuracy: 0.9815\n",
            "Epoch 163/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0675 - accuracy: 0.9790 - val_loss: 0.0628 - val_accuracy: 0.9823\n",
            "Epoch 164/2000\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0667 - accuracy: 0.9810 - val_loss: 0.0640 - val_accuracy: 0.9815\n",
            "Epoch 165/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0679 - accuracy: 0.9797 - val_loss: 0.0628 - val_accuracy: 0.9823\n",
            "Epoch 166/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0702 - accuracy: 0.9792 - val_loss: 0.0643 - val_accuracy: 0.9815\n",
            "Epoch 167/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0705 - accuracy: 0.9792 - val_loss: 0.0601 - val_accuracy: 0.9823\n",
            "Epoch 168/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0671 - accuracy: 0.9808 - val_loss: 0.0604 - val_accuracy: 0.9815\n",
            "Epoch 169/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9818 - val_loss: 0.0607 - val_accuracy: 0.9823\n",
            "Epoch 170/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0643 - accuracy: 0.9818 - val_loss: 0.0603 - val_accuracy: 0.9823\n",
            "Epoch 171/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9818 - val_loss: 0.0715 - val_accuracy: 0.9777\n",
            "Epoch 172/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.9792 - val_loss: 0.0663 - val_accuracy: 0.9808\n",
            "Epoch 173/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0676 - accuracy: 0.9784 - val_loss: 0.0640 - val_accuracy: 0.9808\n",
            "Epoch 174/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0666 - accuracy: 0.9797 - val_loss: 0.0611 - val_accuracy: 0.9838\n",
            "Epoch 175/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0683 - accuracy: 0.9790 - val_loss: 0.0608 - val_accuracy: 0.9838\n",
            "Epoch 176/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0633 - accuracy: 0.9820 - val_loss: 0.0589 - val_accuracy: 0.9823\n",
            "Epoch 177/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0621 - accuracy: 0.9826 - val_loss: 0.0603 - val_accuracy: 0.9838\n",
            "Epoch 178/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0615 - accuracy: 0.9826 - val_loss: 0.0579 - val_accuracy: 0.9846\n",
            "Epoch 179/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0618 - accuracy: 0.9828 - val_loss: 0.0598 - val_accuracy: 0.9846\n",
            "Epoch 180/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0627 - accuracy: 0.9810 - val_loss: 0.0578 - val_accuracy: 0.9823\n",
            "Epoch 181/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0612 - accuracy: 0.9820 - val_loss: 0.0610 - val_accuracy: 0.9815\n",
            "Epoch 182/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0614 - accuracy: 0.9831 - val_loss: 0.0565 - val_accuracy: 0.9846\n",
            "Epoch 183/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.9823 - val_loss: 0.0580 - val_accuracy: 0.9823\n",
            "Epoch 184/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0620 - accuracy: 0.9828 - val_loss: 0.0581 - val_accuracy: 0.9846\n",
            "Epoch 185/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0613 - accuracy: 0.9815 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 186/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0597 - accuracy: 0.9841 - val_loss: 0.0606 - val_accuracy: 0.9838\n",
            "Epoch 187/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0618 - accuracy: 0.9831 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 188/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0594 - accuracy: 0.9828 - val_loss: 0.0554 - val_accuracy: 0.9846\n",
            "Epoch 189/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0586 - accuracy: 0.9843 - val_loss: 0.0626 - val_accuracy: 0.9823\n",
            "Epoch 190/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0596 - accuracy: 0.9831 - val_loss: 0.0543 - val_accuracy: 0.9831\n",
            "Epoch 191/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0579 - accuracy: 0.9836 - val_loss: 0.0564 - val_accuracy: 0.9846\n",
            "Epoch 192/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0608 - accuracy: 0.9815 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 193/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0612 - accuracy: 0.9828 - val_loss: 0.0533 - val_accuracy: 0.9838\n",
            "Epoch 194/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0577 - accuracy: 0.9849 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
            "Epoch 195/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0578 - accuracy: 0.9836 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 196/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0567 - accuracy: 0.9841 - val_loss: 0.0533 - val_accuracy: 0.9831\n",
            "Epoch 197/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0572 - accuracy: 0.9841 - val_loss: 0.0534 - val_accuracy: 0.9831\n",
            "Epoch 198/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0565 - accuracy: 0.9841 - val_loss: 0.0527 - val_accuracy: 0.9838\n",
            "Epoch 199/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0562 - accuracy: 0.9838 - val_loss: 0.0536 - val_accuracy: 0.9846\n",
            "Epoch 200/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0568 - accuracy: 0.9831 - val_loss: 0.0621 - val_accuracy: 0.9808\n",
            "Epoch 201/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9823 - val_loss: 0.0670 - val_accuracy: 0.9792\n",
            "Epoch 202/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0594 - accuracy: 0.9846 - val_loss: 0.0550 - val_accuracy: 0.9846\n",
            "Epoch 203/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0557 - accuracy: 0.9843 - val_loss: 0.0525 - val_accuracy: 0.9846\n",
            "Epoch 204/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9854 - val_loss: 0.0526 - val_accuracy: 0.9846\n",
            "Epoch 205/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0560 - accuracy: 0.9846 - val_loss: 0.0519 - val_accuracy: 0.9854\n",
            "Epoch 206/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 0.9841 - val_loss: 0.0515 - val_accuracy: 0.9838\n",
            "Epoch 207/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0547 - accuracy: 0.9836 - val_loss: 0.0507 - val_accuracy: 0.9831\n",
            "Epoch 208/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0540 - accuracy: 0.9849 - val_loss: 0.0505 - val_accuracy: 0.9831\n",
            "Epoch 209/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0543 - accuracy: 0.9846 - val_loss: 0.0516 - val_accuracy: 0.9846\n",
            "Epoch 210/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0551 - accuracy: 0.9836 - val_loss: 0.0514 - val_accuracy: 0.9854\n",
            "Epoch 211/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0547 - accuracy: 0.9849 - val_loss: 0.0501 - val_accuracy: 0.9846\n",
            "Epoch 212/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0546 - accuracy: 0.9849 - val_loss: 0.0515 - val_accuracy: 0.9846\n",
            "Epoch 213/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0564 - accuracy: 0.9849 - val_loss: 0.0486 - val_accuracy: 0.9838\n",
            "Epoch 214/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0570 - accuracy: 0.9851 - val_loss: 0.0518 - val_accuracy: 0.9854\n",
            "Epoch 215/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0541 - accuracy: 0.9851 - val_loss: 0.0485 - val_accuracy: 0.9846\n",
            "Epoch 216/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0535 - accuracy: 0.9856 - val_loss: 0.0487 - val_accuracy: 0.9831\n",
            "Epoch 217/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0531 - accuracy: 0.9851 - val_loss: 0.0500 - val_accuracy: 0.9846\n",
            "Epoch 218/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0541 - accuracy: 0.9846 - val_loss: 0.0479 - val_accuracy: 0.9831\n",
            "Epoch 219/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0561 - accuracy: 0.9836 - val_loss: 0.0491 - val_accuracy: 0.9846\n",
            "Epoch 220/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9854 - val_loss: 0.0472 - val_accuracy: 0.9838\n",
            "Epoch 221/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0540 - accuracy: 0.9854 - val_loss: 0.0477 - val_accuracy: 0.9854\n",
            "Epoch 222/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0522 - accuracy: 0.9856 - val_loss: 0.0510 - val_accuracy: 0.9846\n",
            "Epoch 223/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0527 - accuracy: 0.9846 - val_loss: 0.0487 - val_accuracy: 0.9869\n",
            "Epoch 224/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0523 - accuracy: 0.9851 - val_loss: 0.0501 - val_accuracy: 0.9838\n",
            "Epoch 225/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 0.9854 - val_loss: 0.0490 - val_accuracy: 0.9854\n",
            "Epoch 226/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9851 - val_loss: 0.0478 - val_accuracy: 0.9854\n",
            "Epoch 227/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0499 - accuracy: 0.9879 - val_loss: 0.0501 - val_accuracy: 0.9854\n",
            "Epoch 228/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.9864 - val_loss: 0.0509 - val_accuracy: 0.9846\n",
            "Epoch 229/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0578 - accuracy: 0.9823 - val_loss: 0.0456 - val_accuracy: 0.9854\n",
            "Epoch 230/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0568 - accuracy: 0.9836 - val_loss: 0.0516 - val_accuracy: 0.9838\n",
            "Epoch 231/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0562 - accuracy: 0.9820 - val_loss: 0.0477 - val_accuracy: 0.9854\n",
            "Epoch 232/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0511 - accuracy: 0.9856 - val_loss: 0.0485 - val_accuracy: 0.9854\n",
            "Epoch 233/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0491 - accuracy: 0.9877 - val_loss: 0.0458 - val_accuracy: 0.9831\n",
            "Epoch 234/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0492 - accuracy: 0.9872 - val_loss: 0.0464 - val_accuracy: 0.9854\n",
            "Epoch 235/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0510 - accuracy: 0.9856 - val_loss: 0.0475 - val_accuracy: 0.9846\n",
            "Epoch 236/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.9846 - val_loss: 0.0474 - val_accuracy: 0.9862\n",
            "Epoch 237/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0495 - accuracy: 0.9859 - val_loss: 0.0497 - val_accuracy: 0.9846\n",
            "Epoch 238/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0500 - accuracy: 0.9859 - val_loss: 0.0460 - val_accuracy: 0.9854\n",
            "Epoch 239/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0491 - accuracy: 0.9869 - val_loss: 0.0478 - val_accuracy: 0.9846\n",
            "Epoch 240/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0494 - accuracy: 0.9867 - val_loss: 0.0487 - val_accuracy: 0.9854\n",
            "Epoch 241/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0489 - accuracy: 0.9867 - val_loss: 0.0457 - val_accuracy: 0.9854\n",
            "Epoch 242/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9864 - val_loss: 0.0469 - val_accuracy: 0.9846\n",
            "Epoch 243/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0493 - accuracy: 0.9864 - val_loss: 0.0450 - val_accuracy: 0.9862\n",
            "Epoch 244/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0478 - accuracy: 0.9885 - val_loss: 0.0456 - val_accuracy: 0.9862\n",
            "Epoch 245/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9877 - val_loss: 0.0436 - val_accuracy: 0.9854\n",
            "Epoch 246/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 0.9861 - val_loss: 0.0444 - val_accuracy: 0.9854\n",
            "Epoch 247/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9872 - val_loss: 0.0563 - val_accuracy: 0.9808\n",
            "Epoch 248/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9833 - val_loss: 0.0609 - val_accuracy: 0.9762\n",
            "Epoch 249/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9846 - val_loss: 0.0525 - val_accuracy: 0.9823\n",
            "Epoch 250/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0584 - accuracy: 0.9831 - val_loss: 0.0444 - val_accuracy: 0.9862\n",
            "Epoch 251/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0543 - accuracy: 0.9854 - val_loss: 0.0455 - val_accuracy: 0.9862\n",
            "Epoch 252/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0522 - accuracy: 0.9861 - val_loss: 0.0566 - val_accuracy: 0.9823\n",
            "Epoch 253/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0528 - accuracy: 0.9854 - val_loss: 0.0424 - val_accuracy: 0.9846\n",
            "Epoch 254/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9869 - val_loss: 0.0458 - val_accuracy: 0.9846\n",
            "Epoch 255/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0480 - accuracy: 0.9872 - val_loss: 0.0498 - val_accuracy: 0.9846\n",
            "Epoch 256/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9869 - val_loss: 0.0450 - val_accuracy: 0.9869\n",
            "Epoch 257/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0485 - accuracy: 0.9864 - val_loss: 0.0436 - val_accuracy: 0.9862\n",
            "Epoch 258/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0495 - accuracy: 0.9856 - val_loss: 0.0440 - val_accuracy: 0.9862\n",
            "Epoch 259/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.9864 - val_loss: 0.0431 - val_accuracy: 0.9854\n",
            "Epoch 260/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 0.9867 - val_loss: 0.0432 - val_accuracy: 0.9846\n",
            "Epoch 261/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9877 - val_loss: 0.0418 - val_accuracy: 0.9862\n",
            "Epoch 262/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9874 - val_loss: 0.0435 - val_accuracy: 0.9869\n",
            "Epoch 263/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0468 - accuracy: 0.9874 - val_loss: 0.0439 - val_accuracy: 0.9854\n",
            "Epoch 264/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0459 - accuracy: 0.9879 - val_loss: 0.0421 - val_accuracy: 0.9862\n",
            "Epoch 265/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0463 - accuracy: 0.9885 - val_loss: 0.0457 - val_accuracy: 0.9846\n",
            "Epoch 266/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0460 - accuracy: 0.9877 - val_loss: 0.0449 - val_accuracy: 0.9854\n",
            "Epoch 267/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0495 - accuracy: 0.9869 - val_loss: 0.0433 - val_accuracy: 0.9869\n",
            "Epoch 268/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0507 - accuracy: 0.9864 - val_loss: 0.0419 - val_accuracy: 0.9877\n",
            "Epoch 269/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0477 - accuracy: 0.9877 - val_loss: 0.0420 - val_accuracy: 0.9869\n",
            "Epoch 270/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0463 - accuracy: 0.9874 - val_loss: 0.0441 - val_accuracy: 0.9862\n",
            "Epoch 271/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0468 - accuracy: 0.9877 - val_loss: 0.0443 - val_accuracy: 0.9862\n",
            "Epoch 272/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0452 - accuracy: 0.9892 - val_loss: 0.0410 - val_accuracy: 0.9869\n",
            "Epoch 273/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0456 - accuracy: 0.9882 - val_loss: 0.0419 - val_accuracy: 0.9862\n",
            "Epoch 274/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0451 - accuracy: 0.9890 - val_loss: 0.0416 - val_accuracy: 0.9846\n",
            "Epoch 275/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0455 - accuracy: 0.9885 - val_loss: 0.0415 - val_accuracy: 0.9869\n",
            "Epoch 276/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0449 - accuracy: 0.9882 - val_loss: 0.0424 - val_accuracy: 0.9869\n",
            "Epoch 277/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9887 - val_loss: 0.0413 - val_accuracy: 0.9877\n",
            "Epoch 278/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0441 - accuracy: 0.9892 - val_loss: 0.0425 - val_accuracy: 0.9877\n",
            "Epoch 279/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0471 - accuracy: 0.9885 - val_loss: 0.0435 - val_accuracy: 0.9869\n",
            "Epoch 280/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0469 - accuracy: 0.9867 - val_loss: 0.0420 - val_accuracy: 0.9869\n",
            "Epoch 281/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0453 - accuracy: 0.9887 - val_loss: 0.0460 - val_accuracy: 0.9854\n",
            "Epoch 282/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0463 - accuracy: 0.9872 - val_loss: 0.0410 - val_accuracy: 0.9869\n",
            "Epoch 283/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0443 - accuracy: 0.9890 - val_loss: 0.0448 - val_accuracy: 0.9862\n",
            "Epoch 284/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0460 - accuracy: 0.9879 - val_loss: 0.0417 - val_accuracy: 0.9869\n",
            "Epoch 285/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0441 - accuracy: 0.9892 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
            "Epoch 286/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0442 - accuracy: 0.9890 - val_loss: 0.0403 - val_accuracy: 0.9869\n",
            "Epoch 287/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0444 - accuracy: 0.9887 - val_loss: 0.0408 - val_accuracy: 0.9862\n",
            "Epoch 288/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9887 - val_loss: 0.0410 - val_accuracy: 0.9877\n",
            "Epoch 289/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0452 - accuracy: 0.9887 - val_loss: 0.0407 - val_accuracy: 0.9869\n",
            "Epoch 290/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0462 - accuracy: 0.9890 - val_loss: 0.0435 - val_accuracy: 0.9877\n",
            "Epoch 291/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.9864 - val_loss: 0.0404 - val_accuracy: 0.9877\n",
            "Epoch 292/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0460 - accuracy: 0.9887 - val_loss: 0.0406 - val_accuracy: 0.9877\n",
            "Epoch 293/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0452 - accuracy: 0.9882 - val_loss: 0.0410 - val_accuracy: 0.9877\n",
            "Epoch 294/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9892 - val_loss: 0.0404 - val_accuracy: 0.9885\n",
            "Epoch 295/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0436 - accuracy: 0.9887 - val_loss: 0.0414 - val_accuracy: 0.9862\n",
            "Epoch 296/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9895 - val_loss: 0.0396 - val_accuracy: 0.9877\n",
            "Epoch 297/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 0.9885 - val_loss: 0.0397 - val_accuracy: 0.9877\n",
            "Epoch 298/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0435 - accuracy: 0.9887 - val_loss: 0.0438 - val_accuracy: 0.9869\n",
            "Epoch 299/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9895 - val_loss: 0.0447 - val_accuracy: 0.9846\n",
            "Epoch 300/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0440 - accuracy: 0.9892 - val_loss: 0.0417 - val_accuracy: 0.9862\n",
            "Epoch 301/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9890 - val_loss: 0.0399 - val_accuracy: 0.9877\n",
            "Epoch 302/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0439 - accuracy: 0.9885 - val_loss: 0.0393 - val_accuracy: 0.9869\n",
            "Epoch 303/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0434 - accuracy: 0.9885 - val_loss: 0.0397 - val_accuracy: 0.9877\n",
            "Epoch 304/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9890 - val_loss: 0.0393 - val_accuracy: 0.9869\n",
            "Epoch 305/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0427 - accuracy: 0.9895 - val_loss: 0.0389 - val_accuracy: 0.9877\n",
            "Epoch 306/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9890 - val_loss: 0.0401 - val_accuracy: 0.9877\n",
            "Epoch 307/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0428 - accuracy: 0.9882 - val_loss: 0.0437 - val_accuracy: 0.9838\n",
            "Epoch 308/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9890 - val_loss: 0.0419 - val_accuracy: 0.9862\n",
            "Epoch 309/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0450 - accuracy: 0.9887 - val_loss: 0.0428 - val_accuracy: 0.9862\n",
            "Epoch 310/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9885 - val_loss: 0.0418 - val_accuracy: 0.9846\n",
            "Epoch 311/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0426 - accuracy: 0.9900 - val_loss: 0.0397 - val_accuracy: 0.9862\n",
            "Epoch 312/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0432 - accuracy: 0.9892 - val_loss: 0.0417 - val_accuracy: 0.9862\n",
            "Epoch 313/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0448 - accuracy: 0.9885 - val_loss: 0.0420 - val_accuracy: 0.9854\n",
            "Epoch 314/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9892 - val_loss: 0.0473 - val_accuracy: 0.9831\n",
            "Epoch 315/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0472 - accuracy: 0.9874 - val_loss: 0.0422 - val_accuracy: 0.9869\n",
            "Epoch 316/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0438 - accuracy: 0.9895 - val_loss: 0.0408 - val_accuracy: 0.9869\n",
            "Epoch 317/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9885 - val_loss: 0.0423 - val_accuracy: 0.9862\n",
            "Epoch 318/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0419 - accuracy: 0.9900 - val_loss: 0.0394 - val_accuracy: 0.9877\n",
            "Epoch 319/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0436 - accuracy: 0.9890 - val_loss: 0.0431 - val_accuracy: 0.9854\n",
            "Epoch 320/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0438 - accuracy: 0.9885 - val_loss: 0.0408 - val_accuracy: 0.9862\n",
            "Epoch 321/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9890 - val_loss: 0.0392 - val_accuracy: 0.9885\n",
            "Epoch 322/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0420 - accuracy: 0.9897 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
            "Epoch 323/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9900 - val_loss: 0.0388 - val_accuracy: 0.9877\n",
            "Epoch 324/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9892 - val_loss: 0.0382 - val_accuracy: 0.9885\n",
            "Epoch 325/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0408 - accuracy: 0.9908 - val_loss: 0.0407 - val_accuracy: 0.9862\n",
            "Epoch 326/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0410 - accuracy: 0.9897 - val_loss: 0.0394 - val_accuracy: 0.9877\n",
            "Epoch 327/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0420 - accuracy: 0.9892 - val_loss: 0.0396 - val_accuracy: 0.9885\n",
            "Epoch 328/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0420 - accuracy: 0.9892 - val_loss: 0.0393 - val_accuracy: 0.9877\n",
            "Epoch 329/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 0.9910 - val_loss: 0.0401 - val_accuracy: 0.9869\n",
            "Epoch 330/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9895 - val_loss: 0.0427 - val_accuracy: 0.9869\n",
            "Epoch 331/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9890 - val_loss: 0.0391 - val_accuracy: 0.9885\n",
            "Epoch 332/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 0.9897 - val_loss: 0.0386 - val_accuracy: 0.9885\n",
            "Epoch 333/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0407 - accuracy: 0.9902 - val_loss: 0.0399 - val_accuracy: 0.9869\n",
            "Epoch 334/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9897 - val_loss: 0.0386 - val_accuracy: 0.9892\n",
            "Epoch 335/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9897 - val_loss: 0.0382 - val_accuracy: 0.9885\n",
            "Epoch 336/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0404 - accuracy: 0.9900 - val_loss: 0.0387 - val_accuracy: 0.9892\n",
            "Epoch 337/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0407 - accuracy: 0.9910 - val_loss: 0.0391 - val_accuracy: 0.9885\n",
            "Epoch 338/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9885 - val_loss: 0.0389 - val_accuracy: 0.9885\n",
            "Epoch 339/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0437 - accuracy: 0.9890 - val_loss: 0.0499 - val_accuracy: 0.9808\n",
            "Epoch 340/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 0.9892 - val_loss: 0.0447 - val_accuracy: 0.9846\n",
            "Epoch 341/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0436 - accuracy: 0.9895 - val_loss: 0.0426 - val_accuracy: 0.9838\n",
            "Epoch 342/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0415 - accuracy: 0.9905 - val_loss: 0.0381 - val_accuracy: 0.9885\n",
            "Epoch 343/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0401 - accuracy: 0.9897 - val_loss: 0.0384 - val_accuracy: 0.9892\n",
            "Epoch 344/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9902 - val_loss: 0.0380 - val_accuracy: 0.9892\n",
            "Epoch 345/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0421 - accuracy: 0.9895 - val_loss: 0.0398 - val_accuracy: 0.9892\n",
            "Epoch 346/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9890 - val_loss: 0.0380 - val_accuracy: 0.9900\n",
            "Epoch 347/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0414 - accuracy: 0.9900 - val_loss: 0.0396 - val_accuracy: 0.9885\n",
            "Epoch 348/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0406 - accuracy: 0.9905 - val_loss: 0.0391 - val_accuracy: 0.9885\n",
            "Epoch 349/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0418 - accuracy: 0.9908 - val_loss: 0.0383 - val_accuracy: 0.9892\n",
            "Epoch 350/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0412 - accuracy: 0.9902 - val_loss: 0.0390 - val_accuracy: 0.9892\n",
            "Epoch 351/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9897 - val_loss: 0.0376 - val_accuracy: 0.9892\n",
            "Epoch 352/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9910 - val_loss: 0.0376 - val_accuracy: 0.9892\n",
            "Epoch 353/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0407 - accuracy: 0.9895 - val_loss: 0.0379 - val_accuracy: 0.9892\n",
            "Epoch 354/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9905 - val_loss: 0.0393 - val_accuracy: 0.9885\n",
            "Epoch 355/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0428 - accuracy: 0.9887 - val_loss: 0.0374 - val_accuracy: 0.9900\n",
            "Epoch 356/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 0.9897 - val_loss: 0.0378 - val_accuracy: 0.9900\n",
            "Epoch 357/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.9900 - val_loss: 0.0380 - val_accuracy: 0.9900\n",
            "Epoch 358/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 0.0414 - val_accuracy: 0.9869\n",
            "Epoch 359/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9902 - val_loss: 0.0384 - val_accuracy: 0.9900\n",
            "Epoch 360/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0393 - accuracy: 0.9902 - val_loss: 0.0377 - val_accuracy: 0.9892\n",
            "Epoch 361/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9895 - val_loss: 0.0390 - val_accuracy: 0.9885\n",
            "Epoch 362/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0419 - accuracy: 0.9897 - val_loss: 0.0390 - val_accuracy: 0.9908\n",
            "Epoch 363/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0402 - accuracy: 0.9897 - val_loss: 0.0463 - val_accuracy: 0.9831\n",
            "Epoch 364/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0440 - accuracy: 0.9887 - val_loss: 0.0459 - val_accuracy: 0.9831\n",
            "Epoch 365/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0436 - accuracy: 0.9895 - val_loss: 0.0537 - val_accuracy: 0.9800\n",
            "Epoch 366/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0469 - accuracy: 0.9874 - val_loss: 0.0433 - val_accuracy: 0.9846\n",
            "Epoch 367/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9892 - val_loss: 0.0388 - val_accuracy: 0.9900\n",
            "Epoch 368/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9908 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
            "Epoch 369/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.9890 - val_loss: 0.0376 - val_accuracy: 0.9900\n",
            "Epoch 370/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0412 - accuracy: 0.9897 - val_loss: 0.0389 - val_accuracy: 0.9885\n",
            "Epoch 371/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0422 - accuracy: 0.9897 - val_loss: 0.0475 - val_accuracy: 0.9831\n",
            "Epoch 372/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.9897 - val_loss: 0.0377 - val_accuracy: 0.9892\n",
            "Epoch 373/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0390 - accuracy: 0.9913 - val_loss: 0.0368 - val_accuracy: 0.9900\n",
            "Epoch 374/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0394 - accuracy: 0.9908 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
            "Epoch 375/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0391 - accuracy: 0.9900 - val_loss: 0.0379 - val_accuracy: 0.9885\n",
            "Epoch 376/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0399 - accuracy: 0.9895 - val_loss: 0.0387 - val_accuracy: 0.9885\n",
            "Epoch 377/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9900 - val_loss: 0.0395 - val_accuracy: 0.9877\n",
            "Epoch 378/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0394 - accuracy: 0.9905 - val_loss: 0.0474 - val_accuracy: 0.9831\n",
            "Epoch 379/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0449 - accuracy: 0.9882 - val_loss: 0.0422 - val_accuracy: 0.9838\n",
            "Epoch 380/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9897 - val_loss: 0.0380 - val_accuracy: 0.9885\n",
            "Epoch 381/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0410 - accuracy: 0.9897 - val_loss: 0.0402 - val_accuracy: 0.9862\n",
            "Epoch 382/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0453 - accuracy: 0.9885 - val_loss: 0.0399 - val_accuracy: 0.9877\n",
            "Epoch 383/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 0.9892 - val_loss: 0.0374 - val_accuracy: 0.9900\n",
            "Epoch 384/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0395 - accuracy: 0.9892 - val_loss: 0.0381 - val_accuracy: 0.9885\n",
            "Epoch 385/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0423 - accuracy: 0.9900 - val_loss: 0.0393 - val_accuracy: 0.9877\n",
            "Epoch 386/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9892 - val_loss: 0.0450 - val_accuracy: 0.9831\n",
            "Epoch 387/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 0.9897 - val_loss: 0.0415 - val_accuracy: 0.9869\n",
            "Epoch 388/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0393 - accuracy: 0.9908 - val_loss: 0.0381 - val_accuracy: 0.9900\n",
            "Epoch 389/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9897 - val_loss: 0.0393 - val_accuracy: 0.9900\n",
            "Epoch 390/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0419 - accuracy: 0.9902 - val_loss: 0.0421 - val_accuracy: 0.9877\n",
            "Epoch 391/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0437 - accuracy: 0.9882 - val_loss: 0.0387 - val_accuracy: 0.9892\n",
            "Epoch 392/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0410 - accuracy: 0.9887 - val_loss: 0.0378 - val_accuracy: 0.9900\n",
            "Epoch 393/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0401 - accuracy: 0.9892 - val_loss: 0.0374 - val_accuracy: 0.9908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#history에 저장된 학습 결과를 확인\n",
        "hist_df=pd.DataFrame(history.history)\n",
        "hist_df\n",
        "\n",
        "#y_vloss에 테스트셋(여기서는 검증셋)의 오차 저장\n",
        "#model.fit결과 중 history.history에 loss,val_loss등이 저장되어있음\n",
        "y_vloss=hist_df['val_loss']\n",
        "\n",
        "#y_loss에 학습셋의 오차 저장\n",
        "y_loss=hist_df['loss']\n",
        "\n",
        "#x값을 지정하고 테스트셋(검증셋)의 오차는 빨간색으로, 학습셋의 오차를 파란색으로\n",
        "x_len=np.arange(len(y_loss)) #Epoch당 loss가 들어있으므로 x축으로 사용가능\n",
        "plt.plot(x_len,y_vloss,\"o\",c=\"red\",markersize=2,label='Testset_loss')\n",
        "plt.plot(x_len,y_loss,\"o\",c=\"blue\",markersize=2,label='Trainser_loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "vKMHOY0qbayi",
        "outputId": "69527785-36c5-4c82-c70c-e192bdadcc3a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.데이터 수집. 텍스트 리뷰 자료 지정, 긍정 리뷰는 1, 부정 리뷰는 0\n",
        "docs=[\"너무 재밌네요\",\"최고예요\",\"참 잘 만든 영화네요\",\"추첞하고 싶은 영화입니다.\",\"한번 더 보고싶네요\",\n",
        "      \"글쎄요\",\"별로예요\",\"생각보다 지루하네요\",\"연기가 어색해요\",\"재미없어요\"]\n",
        "classes=array([1,1,1,1,1,0,0,0,0,0])\n",
        "\n",
        "#토큰화\n",
        "token=Tokenizer()\n",
        "token.fit_on_text(docs)\n",
        "print(token.word_index)\n",
        "\n",
        "x=token.texts_to_sequences(docs)\n",
        "print(\"\\n리뷰 텍스트, 토큰화 결과:\\n\",x)\n",
        "\n",
        "#패딩. 서로 다른 길이의 데이터를 4로 맞추어 줌. 보충자료 확인\n",
        "padded_x=pad.sequences(x,4)\n",
        "print(\"\\n패딩 결과:\\n\",padded_x)\n",
        "\n",
        "#임베딩에 입력될 단어의 수를 지정\n",
        "word_size=len(token.word_index)+1\n",
        "\n",
        "#2.모델생성 word embedding 포함\n",
        "model.Sequential()\n",
        "model.add(Embedding(word_size,8,input_length=4))\n"
      ],
      "metadata": {
        "id": "SRtXkIfVe3Za"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}